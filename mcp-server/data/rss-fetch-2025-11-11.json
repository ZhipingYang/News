{
  "ai_programming": [
    {
      "title": "2025.8 release introduces Stack Overflow Internal: The next generation of enterprise knowledge intelligence",
      "link": "https://stackoverflow.blog/2025/11/12/2025-8-release-introduces-stack-overflow-internal-the-next-generation-of-enterprise-knowledge-intelligence/",
      "description": "Today, weâ€™re excited to introduce Stack Overflow Internalâ€”the next evolution of our enterprise platform and the future of Stack Overflow for Teams.",
      "pubDate": "Wed, 12 Nov 2025 15:00:00 GMT",
      "source": "Stack Overflow Blog",
      "sourceUrl": "https://stackoverflow.blog/feed/",
      "credibility": 0.85,
      "category": "tech_news"
    },
    {
      "title": "[Boost]",
      "link": "https://dev.to/dineshrathee12/-d63",
      "description": "How to Set Up the OpenAI API with Python and Flask\ndan ãƒ» Feb 28 '24\n#python\n        #flask\n        #openai\n        #ai",
      "pubDate": "Wed, 12 Nov 2025 05:05:10 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "Predictive Habits: Unlocking Human Behavior with AI Agents",
      "link": "https://dev.to/arvind_sundararajan/predictive-habits-unlocking-human-behavior-with-ai-agents-1g0k",
      "description": "Predictive Habits: Unlocking Human Behavior with AI Agents\n\n\nImagine predicting traffic flow in a city, anticipating the spread of a new virus, or even optimizing staff workflows in a bustling hospital. The key? Understanding and simulating human routines. What if we could build AI that learns and predicts the actions of individuals within a system?\nAt the heart of this lies a novel approach: representing individuals as autonomous agents, each governed by a set of learned routines. These agents aren't just reacting; they're proactively executing established patterns of behavior based on environmental cues and internal motivations. The real innovation happens when we tie actions to individual needs, desires, and capabilities in a structured model.\nThink of it like this: instead of coding rigid rules for every possible scenario, we equip our AI with the ability to learn and adapt routines as it observes and interacts with data. Itâ€™s like teaching a virtual person to bake a cake â€“ they start with a recipe (a routine), but over time, they learn to adjust the ingredients and baking time based on their own preferences and the available ingredients, leading to a personalized and optimized cake (behavior).\nBenefits for Developers:\n  More Realistic Simulations: Create environments that more accurately reflect human behavior.\n  Predictive Power: Anticipate future trends and potential bottlenecks.\n  Optimized Resource Allocation: Improve efficiency in complex systems.\n  Personalized User Experiences: Tailor services and interfaces based on individual routines.\n  Data-Driven Decision Making: Gain deeper insights into human behavior from simulation data.\n  Scalable Solutions: Easily adapt simulations to larger populations and more complex scenarios.\nOne major implementation challenge is ensuring the model doesn't overfit to specific datasets. Carefully balancing the complexity of the routines with the available data is crucial for generalizability.\nUltimately, this AI-driven approach allows us to move beyond reactive analysis and embrace proactive prediction. By simulating human routines, we can unlock new possibilities in urban planning, public health, and countless other fields. This approach opens the door to a future where AI helps us understand, anticipate, and ultimately improve the way we live.\nRelated Keywords: Human behavior modeling, Routine analysis, Agent-based simulation, Social practice theory, Behavioral patterns, Predictive modeling, AI in social science, Urban planning, Public health, Traffic simulation, Crowd behavior, Decision-making, Computational sociology, Machine learning, Pattern recognition, Data analysis, Behavioral AI, Autonomous agents, Complex systems, Digital anthropology, Human-computer interaction",
      "pubDate": "Wed, 12 Nov 2025 05:02:04 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "Diversification Strategies Using AI-Powered Insights",
      "link": "https://dev.to/globridge-tech/diversification-strategies-using-ai-powered-insights-3kh6",
      "description": "Diversification has long been a cornerstone of sound investing â€” the timeless advice of â€œnot putting all your eggs in one basketâ€ still holds true. However, in todayâ€™s fast-paced and data-driven financial world, traditional diversification techniques are no longer enough to safeguard portfolios against volatility and uncertainty. The complexity of global markets, combined with the speed of information flow, demands a smarter, more adaptive approach.\nEnter Artificial Intelligence (AI) â€” the game-changer in modern portfolio management. With its ability to process massive amounts of data, identify hidden correlations, and predict market trends, AI is enabling investors to construct and maintain portfolios that are not just diversified, but intelligently diversified.\nIn this article, weâ€™ll explore how AI-powered insights are revolutionizing diversification strategies, the technologies behind these advancements, and how investors can leverage them for long-term success.\n\n1. The Traditional Approach to Diversification\nTraditional diversification involves spreading investments across different asset classes â€” such as equities, bonds, commodities, and real estate â€” to minimize exposure to any single risk. For example, when stocks fall, bonds may rise, cushioning the portfolioâ€™s overall performance.\nHowever, traditional diversification methods often rely on historical data, static models, and linear assumptions. These methods assume that correlations between asset classes remain relatively stable over time. But in todayâ€™s interconnected global economy, correlations shift rapidly. A geopolitical conflict, a change in monetary policy, or even a social media trend can alter market dynamics in minutes.\nAs a result, traditional diversification models may fail to protect investors from systemic risks â€” when all asset classes move together during a crisis, leaving â€œdiversifiedâ€ portfolios exposed.\n2. How AI Transforms Diversification Strategies\nArtificial Intelligence enhances diversification by introducing real-time analytics, machine learning algorithms, and predictive modeling that adapt continuously to evolving market conditions. Letâ€™s look at how AI does this.\na. Deep Data Analysis and Market Pattern Recognition\nAI systems can analyze structured and unstructured data â€” from stock prices and earnings reports to news sentiment, social media chatter, and even weather patterns. By scanning through this massive data pool, AI identifies trends and correlations that humans might overlook.\nreal-world behavior, not just asset categories.\nb. Correlation Mapping and Hidden Relationships\nMachine learning algorithms can uncover non-linear correlations â€” subtle relationships that donâ€™t appear in standard correlation matrices. This allows investors to construct portfolios that include assets with true independence rather than just apparent diversification.\nFor instance, AI might detect that a particular emerging-market bond has an inverse relationship with a U.S. tech ETF under specific macroeconomic conditions. Diversifying across such uncorrelated assets leads to more resilient portfolios.\nc. Predictive Modeling for Volatility and Risk Forecasting\nAI doesnâ€™t just analyze the past â€” it anticipates the future. By using predictive analytics, AI can forecast how assets might behave under various market scenarios. Investors can use these predictions to adjust their diversification strategy before volatility strikes.\nd. Dynamic and Automated Rebalancing\nTraditional portfolios are often rebalanced quarterly or annually. But markets move daily â€” even hourly. AI-powered systems monitor portfolios in real time and rebalance automatically when correlations shift or risk thresholds are breached.\nThis ensures the portfolio remains aligned with the investorâ€™s risk profile and market reality â€” a process known as dynamic diversification.\n3. Real-World Applications of AI in Diversification\nAI isnâ€™t a theoretical concept anymore â€” itâ€™s already reshaping the investment landscape.\nRobo-Advisors: Platforms like Betterment, Wealthfront, and Schwab Intelligent Portfolios use AI algorithms to construct personalized, diversified portfolios based on investorsâ€™ goals, risk tolerance, and time horizons.\nHedge Funds and Institutional Investors: Firms like Bridgewater Associates and Renaissance Technologies use AI models to identify complex macroeconomic linkages, diversify across asset classes, and optimize hedging strategies.\nRetail Investor Tools: Modern AI-based apps help individuals access professional-grade diversification strategies. These platforms provide AI-driven asset recommendations, real-time alerts, and market sentiment analysis.\nThese use cases demonstrate how AI can bring institutional-grade intelligence to all types of investors â€” from large funds to individual traders.\n4. The Benefits of AI-Powered Diversification\nsmarter, faster, and more adaptive decision-making. Here are the key benefits:\n1. Improved Risk Management\n2. Enhanced Portfolio Performance\n3. Real-Time Responsiveness\n4. Personalized Investment Strategies\n5. Reduced Human Bias\n5. The Technology Behind AI Diversification\nTo understand how AI enables smarter diversification, it helps to know the core technologies involved:\nMachine Learning (ML): Identifies trends and patterns in historical and real-time data.\nNatural Language Processing (NLP): Analyzes financial news, reports, and sentiment to capture market mood.\nNeural Networks: Model complex relationships between variables, uncovering subtle interdependencies.\nReinforcement Learning: Continuously improves portfolio strategies through trial and feedback, much like a self-learning system.**\nThese technologies work together to ensure that AI can not only analyze data but also learn and adapt continuously, refining diversification models over time.\n6. Risks, Challenges, and Ethical Considerations\nDespite its power, AI-driven diversification comes with challenges:\nData Bias: AI models are only as good as the data they learn from. Poor or biased data can lead to flawed conclusions.\nAlgorithmic Transparency: Many AI systems operate as â€œblack boxes,â€ making it hard for investors to understand how decisions are made.\nOver-Reliance on Automation: Complete dependence on AI can be risky â€” human judgment and oversight remain essential.\nEthical Use of Data: Responsible AI implementation requires strict data privacy and ethical compliance.\nInvestors should balance the benefits of AI with human experience, oversight, and long-term perspective.\n7. The Future of Diversification in the AI Era\nThe future of diversification will be proactive rather than reactive. As AI continues to evolve, weâ€™ll see:\nHyper-personalized portfolios based on lifestyle and behavioral patterns.\nCross-market intelligence, where AI integrates data from crypto, real estate, and traditional markets simultaneously.\nCollaborative AI-human investment ecosystems, combining machine precision with human intuition.\nThe fusion of human insight and artificial intelligence will mark the next leap in wealth management â€” creating diversification strategies that are not only safer but also more intelligent.\nConclusion\nArtificial Intelligence is fundamentally transforming how investors approach diversification. By combining data analytics, predictive modeling, and continuous learning, AI enables portfolios that are adaptive, resilient, and optimized for changing markets.\nIn a world where financial uncertainty is the only constant, AI-powered diversification isnâ€™t just an advantage â€” itâ€™s a necessity. Those who embrace this technology-driven evolution today will be better positioned for sustainable growth, reduced risk, and long-term investment success.\nAddress: 101 Greenfield Road, E1 1EJ London, United Kingdom",
      "pubDate": "Wed, 12 Nov 2025 04:56:18 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "JSON vs TOON â€” Smarter Data Representation and Token Efficiency in AI",
      "link": "https://dev.to/manikandan/json-vs-toon-smarter-data-representation-and-token-efficiency-in-ai-549f",
      "description": "Introduction\n\n\nIn artificial intelligence (AI) systems â€” especially large language models (LLMs) and generative AI applications â€” data representation plays a crucial role in performance, cost, and interpretability.  \nTraditionally, formats like JSON are used to exchange structured data. However, emerging formats like TOON are designed to optimize token efficiency and AI compatibility, allowing models to process, store, and transmit information more effectively.\nThis article explores JSON vs TOON, how TOON improves token utilization, and why itâ€™s becoming important in AI-driven systems.\nJSON (JavaScript Object Notation) is a lightweight data format used for representing structured data as key-value pairs. Itâ€™s simple, human-readable, and supported across almost all programming languages.\n{\n  \"user\": \"Alice\",\n  \"age\": 25,\n  \"role\": \"Data Scientist\"\n}\n\nPros of JSON:\nUniversally supported\n\nEasy to parse\n\nIdeal for APIs and config files\n\n\n\nCons of JSON:\nRedundant tokens and long keys increase data size\n\nVerbose syntax (quotes, brackets) adds token overhead\n\nInefficient for models that charge or process data per token\n\n\n\n\n  \n  \n  What is TOON?\n\n\nTOON (Token-Optimized Object Notation) is a next-generation structured format optimized for AI model interactions.\n\nWhile JSON focuses on human and machine readability, TOON focuses on compactness, semantic clarity, and token efficiency â€” ideal for use with LLMs, chatbots, and AI pipelines that process structured data.\nMinimize Tokens: Uses shorter representations for repeated fields.\n\n\nAI-friendly Parsing: Easier for token-based models to read contextually.\n\n\nCompression of Redundant Keys: Reduces payload size while maintaining structure.\n\n\nSemantic Awareness: Values and structures are encoded to reduce ambiguity.\n\n\n\nFeature\nJSON\nTOON\n\n\n\n\nSyntax\nText-heavy with quotes, brackets\nMinimal, token-efficient\n\n\nHuman Readability\nExcellent\nGood but more compact\n\n\nAI Token Efficiency\nLow (more tokens per data item)\nHigh (fewer tokens needed)\n\n\nBest Use Case\nAPIs, config files, web data exchange\nAI prompts, fine-tuning, structured AI output\n\n\nSupport\nWidely supported in all languages\nEmerging in AI-focused frameworks\n\n\nParsing Speed (in AI)\nSlower due to verbosity\nFaster and less token-expensive\n\n\n\n{\n  \"question\": \"What is the capital of France?\",\n  \"answer\": \"Paris\",\n  \"confidence\": 0.98\n}\n\n? What is the capital of France\n! Paris\n% 0.98\n\n\nHere, TOONâ€™s compact syntax:\nRemoves unnecessary brackets and quotes\n\nUses symbolic prefixes (?, !, %) to represent semantic meaning\n\nReduces total tokens â€” improving model efficiency and lower API costs\nToken Optimization\n\n\nEach token costs compute and bandwidth in LLM-based systems (like OpenAI or Anthropic models).\n\nTOON reduces total tokens per request, saving up to 30â€“40% in token usage for structured payloads.\nBetter Prompt Control\n\n\nBecause TOON is semantically consistent, AI models understand the intent faster, reducing confusion in responses.\nEfficient Fine-tuning\n\n\nDuring model fine-tuning, compact formats reduce dataset size, making training more efficient and cheaper.\nContext Preservation\n\n\nShorter, structured data fits within context windows more easily â€” allowing longer conversations or additional metadata within the same token limit.\n\n\n\nUse Case\nDescription\n\n\n\n\nPrompt Engineering\nEmbed structured instructions and responses in token-efficient syntax\n\n\nLLM APIs\nMinimize cost by reducing token count in structured input/output\n\n\nDataset Preparation\nStore AI question-answer pairs efficiently for fine-tuning\n\n\nIn-Memory Data for Agents\nUse compact structured formats for reasoning agents (e.g., AutoGPT)\n\n\n\n\n\n\nMetric\nJSON (avg)\nTOON (avg)\n\n\n\n\nTokens per 1k Q/A pairs\n45,000\n29,000\n\n\nParsing speed (ms per 100 ops)\n11.2\n7.6\n\n\nAPI Cost (per million tokens)*\nHigher\n30% lower\n\n\n\n*Assuming GPT-style token billing metrics.\nğŸ”¹ Token-efficient syntax for AI input/output\n\nğŸ”¹ Compact structure reduces payload size and latency\n\nğŸ”¹ Context-fit optimization for LLM memory limits\n\nğŸ”¹ Lower API cost in token-based billing models\n\nğŸ”¹ Semantic clarity for machine interpretation\n\nğŸ”¹ Future-ready for AI-native data representation\n\n\n\n\n  \n  \n  TOON and Token Utilization in AI\n\n\nTOON excels in token utilization â€” a major factor in AI cost and performance.\n\nWhen models like GPT, Claude, or Gemini process structured data, each word, symbol, and punctuation is tokenized. JSONâ€™s verbose structure inflates token counts, while TOONâ€™s minimal symbols reduce that by 30â€“40%, making AI interactions faster and cheaper.\nIn applications with millions of prompt exchanges â€” like conversational agents or fine-tuning datasets â€” the savings compound dramatically, making TOON a strategic choice for AI scalability.\nWhile JSON will remain the standard for general data interchange, TOON is emerging as a purpose-built format for AI systems that care about token count, compactness, and interpretability.\nIn AI-driven applications, especially where cost and token context matter, switching from JSON to TOON can yield significant efficiency improvements without losing structure or meaning.\nIn short: JSON is for systems. TOON is for smart, token-aware AI.\nJSON.org â€” The JSON Data Interchange Standard\n\n\nOpenAI Tokenization Explained\n\n\nTiktoken Library â€” Efficient Token Counting",
      "pubDate": "Wed, 12 Nov 2025 04:53:54 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "Predictive Maintenance of Dust Collection Systems via Acoustic Emission Analysis & Machine Learning",
      "link": "https://dev.to/freederia-research/predictive-maintenance-of-dust-collection-systems-via-acoustic-emission-analysis-machine-learning-17ih",
      "description": "(The following is a research paper draft fulfilling the promptâ€™s requirements. It aims for rigor, practicality, and utilizes established technologies. The total character count significantly exceeds 10,000.)\nAbstract: This paper investigates a novel methodology for predicting failures in industrial dust collection systems utilizing acoustic emission (AE) data and machine learning. Traditional maintenance schedules are often inefficient, leading to both unnecessary downtime and unexpected system failures. This approach leverages real-time AE data correlated with system performance metrics to establish a predictive maintenance paradigm, optimizing maintenance schedules, reducing downtime, and extending system lifespan. The proposed method integrates wavelet-based feature extraction, a Support Vector Machine (SVM) classifier, and a Bayesian optimization loop for adaptive threshold adjustment, resulting in a 92% accuracy in predicting filter clogging and ductwork degradation.\n1. Introduction\nIndustrial dust collection systems are critical for maintaining workplace safety and regulatory compliance. These systems, consisting of hoods, ductwork, filtration units, and fans, are subject to constant wear and tear due to abrasive particulate matter. Traditional maintenance strategies, largely based on time-scheduled replacements, are sub-optimal; they lead to unnecessary component replacements or, conversely, catastrophic failures due to delayed intervention.  This paper proposes a predictive maintenance framework leveraging acoustic emission (AE) analysis and machine learning to address this challenge. AE is the transient elastic stress wave generated by materials undergoing deformation and fracturing. Analyzing AE signals allows for early detection of degradation mechanisms such as filter clogging, duct erosion, and fan bearing failure. Specifically, this study focuses on leveraging AE data from the filtration unit and ductwork to predict impending issues and proactively schedule maintenance activities. The research targets a specific sub-field within ì‘ì—… í™˜ê²½ ì¸¡ì • ì¥ë¹„ (ì†ŒìŒ, ë¶„ì§„, ìœ ê¸°ìš©ì œ ë†ë„): Real-time Monitoring of Particulate Matter Handling Systems.\n2. Background and Related Work\nExisting research on industrial dust collection maintenance predominantly centers on: (1) routine visual inspections, (2) differential pressure measurements across filters, and (3) fan motor vibration analysis.  While these methods provide valuable insights, they often lack the sensitivity to detect early-stage degradation. AE monitoring has been successfully applied in various engineering fields (e.g., aerospace, civil engineering) for structural health monitoring. Several studies have investigated AE for particulate matter detection but rarely in the context of predictive maintenance for entire dust collection systems. Prior work has lacked a robust, adaptive machine learning model capable of correlating complex AE signal patterns with system performance and failure modes.\n3. Methodology\nThe proposed methodology comprises four key stages: Data Acquisition, Feature Extraction, Model Training & Prediction, and Adaptive Threshold Adjustment.\n3.1 Data Acquisition\nAE sensors (Piezoelectric, 100 kHz resonant) were strategically mounted on the following components:\nFiltration Unit: Two sensors positioned on the exterior of the filter housing, capturing AE signals reflecting filter clogging/rupture.\nDuctwork: One sensor placed near a known stress concentration point (elbow) in the ductwork, capturing AE signals indicative of erosion/corrosion.\nSystem Performance Metrics: Concurrent data streams were collected including:\n\n\n Differential Pressure across filters (Pa) â€“ from existing pressure gauges.\n Fan Power Consumption (W) â€“ from motor control unit.\n Airflow Rate (mÂ³/s) â€“ from existing airflow sensors.\nData was sampled at 200 kHz with an 8-bit analog-to-digital converter, and continuously logged for 18 months across a range of industrial settings (woodworking, metal fabrication, chemical processing).\n3.2 Feature Extraction â€“ Wavelet Decomposition\nRaw AE signals are inherently complex and contain irrelevant noise. To extract meaningful features for machine learning, a Discrete Wavelet Transform (DWT) utilizing the Daubechies 4 wavelet was applied. This decomposes the AE signal into different frequency bands, allowing for separation of distinct damage mechanisms. Key features derived from wavelet coefficients included:\nEnergy in each wavelet band (E1-E8).\nSignal-to-Noise Ratio (SNR) in each band.\nKurtosis and Skewness - descriptive statistics capturing signal pulse shapes.\nMathematically, the energy in the i-th wavelet band is calculated as:\nEi = Î£ |ci,j|2,  where ci,j is the wavelet coefficient in band i at level j.\n3.3 Model Training & Prediction â€“ Support Vector Machine (SVM)\nAn SVM classifier was chosen for its ability to effectively handle high-dimensional data and its inherent robustness against overfitting. The extracted features were used to train an SVM with a Radial Basis Function (RBF) kernel. The labels were derived from documented maintenance records, classifying the system state as either \"Healthy\" or \"Degraded\" (requiring maintenance).  The dataset was split into 70% training and 30% testing sets.  The following standard SVM formulation was utilized:\nMaximize:  âˆ‘i Î±i âˆ’ Â½ âˆ‘i,j Î±i Î±j yi yj K(xi, xj)\nSubject to: 0 â‰¤ Î±i â‰¤ C, âˆ‘i Î±i yi = 0\nWhere:\nÎ±i â€“ Lagrange multipliers\nyi â€“ Label (+1 or -1)\nxi â€“ Feature vector\nK(xi, xj) â€“ Kernel function (RBF: exp(-Î³ ||xi - xj||2))\nC â€“ Regularization parameter.\n3.4 Adaptive Threshold Adjustment â€“ Bayesian Optimization\nTo mitigate the impact of varying particulate matter composition and system operating conditions, a Bayesian optimization loop was implemented to dynamically adjust the decision threshold for the SVM classifier.  The objective function to be minimized was the misclassification rate on the test dataset. The Gaussian Process Regression (GPR) model was used to explore the parameter space (SVM threshold) efficiently.\n4. Experimental Results\nThe SVM classifier achieved an overall accuracy of 92% on the testing dataset. The confusion matrix is presented in Table 1.\nTable 1: Confusion Matrix\n\n\n\n\nPredicted Healthy\nPredicted Degraded\n\n\n\n\nActual Healthy\n873\n87\n\n\nActual Degraded\n65\n885\n\n\n\nThe Bayesian optimization loop successfully reduced the misclassification rate by 5% compared to a fixed threshold, demonstrating the effectiveness of the adaptive approach.  Representative AE signal visualizations for â€œHealthyâ€ and â€œDegradedâ€ conditions are shown in Figure 1.\nFigure 1: Representative AE Signal Waveforms â€“ (Healthy vs. Degraded) (Visualization omitted for text-based format)\n5. Scalability and Future Directions\nThe proposed system is designed to be scalable.  The distributed data acquisition network could be expanded to monitor additional system components (e.g., fan bearings) with minimal modification. The SVM model can be readily adapted to incorporate additional features derived from system performance metrics.  Future work will explore the integration of deep learning techniques (e.g., Convolutional Neural Networks) for automated feature extraction directly from raw AE signals.  Real-time anomaly detection based on the learned profiles is also a key area for further investigation. The framework could be extended to incorporate reinforcement learning to optimize maintenance schedules and resource allocation.\n6. Conclusion\nThis paper presents a robust and accurate framework for predictive maintenance of industrial dust collection systems using acoustic emission analysis and machine learning. The integration of wavelet-based feature extraction, an SVM classifier, and Bayesian optimization offers improved accuracy and adaptability compared to traditional maintenance strategies. The methodology has demonstrated its potential to significantly reduce downtime, extend system lifespan, and optimize maintenance operations, providing a valuable tool for industrial facilities. The implemented system effectively addresses a profound theoretical concept, leverages immediately commercializable technologies, and ensures practical application for researchers and technical staff.\n(Total Character Count:  Exceeds 10,000)\nThis research tackles a significant challenge in industrial settings: keeping dust collection systems running efficiently and safely. These systems are vital for worker health and safety, but their traditional maintenance is often inefficient â€“ too early and youâ€™re wasting money and time, too late and you risk breakdowns and potential hazards. This study offers a smart solution by using sound, called acoustic emission (AE), and machine learning to predict when these systems need servicing. Letâ€™s break down how this works, why it's important, and what makes it a step forward.\n1. Research Topic Explanation and Analysis\nIndustrial dust collection systems are essentially complex machines that scrub air of particulate matter â€“ sawdust in a woodworking shop, metal shavings in a fabrication plant, chemicals in a processing facility. They wear down over time, and problems like clogged filters, eroded ductwork, and failing fan bearings eventually lead to reduced efficiency and potential failures.  Think of it like your car â€“ you change the oil regularly to avoid engine problems, but simply scheduling replacements isn't always the best approach. This research aims to create a smarter â€˜oil changeâ€™ schedule for dust collectors, based on their actual condition.\nThe core technologies are Acoustic Emission (AE) and Machine Learning (ML).  Acoustic Emission is a fascinating phenomenon. As materials deform or crack, they release tiny, high-frequency sound waves, often inaudible to humans. These waves are like the early warning signs of damage. Machine Learning, in this case a Support Vector Machine (SVM), is a type of algorithm that can \"learn\" patterns from data. The system trains the SVM using data about the system's behavior â€“ AE signals and performance metrics â€“ to identify the patterns that precede failures.\nWhy these technologies? Traditional methods are reactive â€“ checking filter pressure or fan vibration after a problem has already started. AE allows us to detect damage at a much earlier stage, sometimes before any noticeable performance drop. ML provides the power to analyze the complex mix of signals and data to make accurate predictions. Integrating both is key - AE provides the raw data, ML provides the smarts to interpret it.\nKey Question - Advantages & Limitations: A significant technical advantage lies in AE's sensitivity. It can detect minute changes in material behavior that pressure gauges or vibration sensors might miss. However, AE signals can be noisy and influenced by various factors, making accurate interpretation challenging. The reliance on labelled data (knowing when a component failed) is a limitation; acquiring this data can be time-consuming and expensive. The SVM, while robust, can be computationally intensive with very large datasets, potentially impacting real-time performance.\nTechnology Description: AE sensors are essentially highly sensitive microphones that pick up these tiny vibrations. Their resonant frequency (100 kHz in this study) means they are designed to be particularly good at detecting high-frequency sounds. The DWT (Discrete Wavelet Transform) is where things get clever.  Imagine listening to a song â€“ you hear all the instruments blended together. A wavelet transform is like separating the instruments to hear each one clearly. It breaks down the complex AE signal into different â€œfrequency bands,â€ allowing us to identify specific types of damage. For instance, duct erosion might produce a distinct AE signature compared to filter clogging.\n2. Mathematical Model and Algorithm Explanation\nLetâ€™s look at some of the math behind this. The energy calculation (Ei = Î£ |ci,j|2) is fundamentally about measuring the â€œstrengthâ€ of the signal in each frequency band. 'ci,j' represents the wavelet coefficient - a numerical value telling you how much of that frequency is present in the signal.  Squaring it (|ci,j|2) ensures only positive values are considered, and summing them up gives you a measure of the overall energy.\nThe SVM formulation is more complex. Think of it as drawing a line (or a hyperplane in higher dimensions) to separate â€œhealthyâ€ data points from â€œdegradedâ€ ones. The goal is to find a line that maximizes the margin - the distance from the line to the closest data point on either side. The â€˜Lagrange multipliersâ€™ (Î±i) determine the influence of each data point on the line's position. The kernel function (RBF â€“ exp(-Î³ ||xi - xj||2)) allows the SVM to handle non-linear relationships between features, meaning it can draw curved lines if needed. Gamma (Î³) controls the influence of single training examples.\nBayesian Optimization uses a Gaussian Process Regression (GPR) model. Consider trying to find the highest point on a bumpy landscape blindfolded. GPR helps you find the best spot by building a model of the landscape based on a few exploratory steps.  It estimates the value at any point, and importantly, it also provides a measure of uncertainty, allowing you to focus your search on promising areas. In this case, GPR helps find the optimal SVM threshold that minimizes misclassifications.\n3. Experiment and Data Analysis Method\nThe experiment involves strategically placing AE sensors on filter housings and ductwork elbows, where stress concentrations are likely to occur. They collected data alongside standard performance metrics - differential pressure (measuring how clogged the filters are), fan power consumption (indicating fan strain), and airflow rate. The system ran continuously for 18 months across diverse industrial settings.\nExperimental Setup Description: High-speed data acquisition (200 kHz sampling rate) is crucial. This ensures that even rapid changes in the AE signals are captured. The 8-bit ADC means each signal is measured with 256 levels of resolution. Pressure gauges and airflow sensors, already present in the systems, provided valuable contextual information.\nData Analysis Techniques: Regression analysis can be used to see how AE signal features (energy in specific wavelet bands, SNR, kurtosis) change with differential pressure. Is there a linear or non-linear relationship? Statistical analysis (e.g., t-tests, ANOVA) would then be used to determine if these changes are statistically significant â€“ not just random fluctuations. For example, we might test if the average energy in a specific frequency band is significantly higher when the filter pressure is above a certain threshold.\n4. Research Results and Practicality Demonstration\nThe study achieved a remarkable 92% accuracy in predicting filter clogging and ductwork degradation. The confusion matrix highlights this performance: only a small number of systems were misclassified as healthy when they required maintenance, and vice versa. The Bayesian optimization loop improved accuracy by a further 5%, showing its value in adapting the model to varying conditions. Visualizing AE signals â€“ seeing how they change from the noisy â€œhealthyâ€ waveforms to the more structured â€œdegradedâ€ signals â€“ provides powerful confirmation of the approach.\nResults Explanation: A 92% accuracy is excellent.  Consider existing methods - a visual inspection might miss early signs of filter clogging. Differential pressure only indicates that filters are clogged, not how severely. AE combined with ML offers a much more proactive and precise solution.\nPracticality Demonstration: Imagine a woodworking shop. Instead of replacing filters every month regardless, the system alerts maintenance staff when AE analysis shows significant degradation, allowing them to replace only the necessary filters, saving money and reducing downtime. Similarly, for ductwork, the system can signal imminent erosion, allowing for preventative repairs before a costly leak or collapse occurs.  A deployment-ready system could be packaged in a rugged enclosure with remote access and alerts to maintenance personnel. This could be sold as a service â€“ continuously monitoring the system and offering predictive maintenance recommendations.\n5. Verification Elements and Technical Explanation\nThe core verification element is the robust testing dataset â€“ 18 months of real-world data from diverse settings. The split into 70% training and 30% testing ensures the model generalizes well to unseen data, rather than simply memorizing the training examples. The complexity of the mathematical models underlines the reliability of the approach.\nVerification Process: The fact that the Bayesian optimization loop consistently improved performance (reducing misclassification by 5%) directly validates the algorithm. Furthermore, replicating the testing protocol in other facilities would offer independent verification. Showing explicitly the waveforms, as in Figure 1, allows reproducibility of the method.\nTechnical Reliability: Real-time performance requires efficient algorithms. The SVM, while powerful, might require optimization for extremely high data rates. The adaptive threshold adjustment, through Bayesian optimization, accounts for the fact that conditions can vary with different materials being processed and different operating conditions.\n6. Adding Technical Depth\nThis researchâ€™s primary technical contribution is the integration of wavelet decomposition with an SVM and a Bayesian optimization loop for predictive maintenance, moving beyond simple anomaly detection. The core elegance is in the information extracted at each step. Wavelet decomposition adequately handles the varying frequency composition of AE signals, and the SVMâ€™s advanced kernel function allows for highly reliable classification. The use of Bayesian Optimization, beyond what is used in past papers, enhances the adaptability of the model.\nMany existing studies focus on detecting specific damage mechanisms (like corrosion). This research takes a more holistic approach, predicting overall system degradation based on a combination of factors. While individual components might not be perfectly detected, the overall system health is monitored.\nThis framework offers clear technical advantages and extends the existing state-of-the-art in the field. Further future investigations can explore more advanced strategies, offering improvements in both precision and execution speed.\nConclusion\nThis research presents a compelling case for predictive maintenance in industrial dust collection systems. By combining the power of acoustic emission and machine learning, it offers a more accurate, efficient, and cost-effective approach compared to traditional methods. The deep technical details are well-supported by experimental data and demonstrate the potential for wide-scale adoption across a range of industries aiming to improve safety, reduce downtime, and optimize operational efficiency.\nThis document is a part of the Freederia Research Archive. Explore our complete collection of advanced research at freederia.com/researcharchive, or visit our main portal at freederia.com to learn more about our mission and other initiatives.",
      "pubDate": "Wed, 12 Nov 2025 04:51:21 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "Mono4DGS-HDR: High Dynamic Range 4D Gaussian Splatting from Alternating-exposureMonocular Videos",
      "link": "https://dev.to/paperium/mono4dgs-hdr-high-dynamic-range-4d-gaussian-splatting-from-alternating-exposuremonocular-videos-2lb0",
      "description": "Turn Your Phone Clips into Stunning HDR 3D Scenes\n\n\nEver wondered if a simple video taken on your phone could become a vivid, lifelike 3â€‘D world? Scientists have created a new tool called Mono4DGSâ€‘HDR that does exactly that.\nThis breakthrough opens the door for creators, educators, and hobbyists to share immersive experiences without costly gear.\nthe future of video is already unfolding.\nLetâ€™s keep watching the world in higher definition, one ordinary clip at a time.\nRead article comprehensive review in Paperium.net:\n Mono4DGS-HDR: High Dynamic Range 4D Gaussian Splatting from Alternating-exposureMonocular Videos \nğŸ¤– This analysis and review was primarily generated and structured by an AI . The content is provided for informational and quick-review purposes.",
      "pubDate": "Wed, 12 Nov 2025 04:50:34 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "faster whisperä»å¤šåª’ä½“è¯­éŸ³ææ–™ä¸­æŠ½å–å‡ºæ–‡æœ¬-2",
      "link": "https://dev.to/dragon72463399/faster-whispercong-duo-mei-ti-yu-yin-cai-liao-zhong-chou-qu-chu-wen-ben-2-4hnd",
      "description": "ä¸ºè„šæœ¬æ·»åŠ æ¯ä¸ªéŸ³é¢‘çš„æ—¶é•¿ç»Ÿè®¡å’Œæ¯ä¸ªéŸ³é¢‘è½¬æ¢æ‰€æœ‰çš„è€—æ—¶ç»Ÿè®¡\n\n\n\n  \n  \n  å®‰è£…ä¾èµ–\n\n\n\n\n\npip install faster-whisper pydub\n\n\"\"\"\næ‰¹é‡è½¬å½•å½“å‰ç›®å½•ä¸‹çš„ .mp3 æ–‡ä»¶ï¼Œä½¿ç”¨ faster-whisper\næ–°å¢åŠŸèƒ½ï¼š\n- æ¯ä¸ªéŸ³é¢‘çš„æ—¶é•¿ï¼ˆç§’ï¼‰\n- æ¯ä¸ªéŸ³é¢‘çš„è½¬å½•è€—æ—¶ï¼ˆç§’ï¼‰\n- æ€»è®¡ç»Ÿè®¡ï¼šæ€»éŸ³é¢‘æ—¶é•¿ã€æ€»è½¬å½•è€—æ—¶ã€å¹³å‡å®æ—¶å€ç‡\n\"\"\"\nimport os\nimport sys\nimport time\nfrom pathlib import Path\nfrom typing import List, Tuple\n\nfrom faster_whisper import WhisperModel\nfrom pydub import AudioSegment\n\n\n# ================== é…ç½®åŒº ==================\nMODEL_SIZE = \"small\"      # å¯é€‰: tiny, base, small, medium, large\nDEVICE = \"cpu\"            # cpu æˆ– cuda\nCOMPUTE_TYPE = \"int8\"     # int8, float16, float32 (CPU æ¨è int8)\nVAD_FILTER = True         # å¯ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œå»é™¤é™éŸ³\nOUTPUT_FORMAT = \"txt\"     # åªè¾“å‡º .txt\nVERBOSE = True            # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—\n# ===========================================\n\n\ndef get_audio_duration(audio_path: Path) -> float:\n    \"\"\"ä½¿ç”¨ pydub è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰\"\"\"\n    try:\n        audio = AudioSegment.from_file(str(audio_path))\n        return len(audio) / 1000.0  # æ¯«ç§’ â†’ ç§’\n    except Exception as e:\n        print(f\"æ— æ³•è·å– {audio_path.name} æ—¶é•¿: {e}\", file=sys.stderr)\n        return 0.0\n\n\ndef transcribe_audio(\n    audio_path: Path, model: WhisperModel\n) -> Tuple[str, float, float]:\n    \"\"\"\n    è½¬å½•å•ä¸ªéŸ³é¢‘æ–‡ä»¶\n    è¿”å›: (æ–‡æœ¬å†…å®¹, éŸ³é¢‘æ—¶é•¿ç§’, è½¬å½•è€—æ—¶ç§’)\n    \"\"\"\n    duration = get_audio_duration(audio_path)\n    print(f\"è½¬å½•: {audio_path.name} ({duration:.2f}s) â†’ {audio_path.stem}.txt\")\n\n    start_time = time.perf_counter()\n    segments, info = model.transcribe(\n        str(audio_path),\n        language=None,           # è‡ªåŠ¨æ£€æµ‹\n        beam_size=5,\n        vad_filter=VAD_FILTER,\n        vad_parameters=dict(min_silence_duration_ms=500),\n        word_timestamps=False,\n    )\n    elapsed = time.perf_counter() - start_time\n\n    text_lines = []\n    for segment in segments:\n        line = segment.text.strip()\n        text_lines.append(line)\n        if VERBOSE:\n            print(f\"[{segment.start:06.2f}s --> {segment.end:06.2f}s] {line}\", flush=True)\n\n    return \"\\n\".join(text_lines), duration, elapsed\n\n\ndef format_time(seconds: float) -> str:\n    \"\"\"å°†ç§’æ•°æ ¼å¼åŒ–ä¸º h:mm:ss\"\"\"\n    hours = int(seconds // 3600)\n    minutes = int((seconds % 3600) // 60)\n    secs = seconds % 60\n    return f\"{hours}:{minutes:02d}:{secs:05.2f}\"\n\n\ndef main():\n    print(\"=== faster-whisper æ‰¹é‡è½¬å½•ï¼ˆå¸¦æ—¶é•¿ä¸è€—æ—¶ç»Ÿè®¡ï¼‰===\")\n\n    current_dir = Path(\".\")\n    mp3_files = sorted(current_dir.glob(\"*.mp3\"))\n\n    if not mp3_files:\n        print(\"æœªæ‰¾åˆ° .mp3 æ–‡ä»¶ï¼Œé€€å‡ºã€‚\")\n        return\n\n    # åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰\n    print(f\"æ­£åœ¨åŠ è½½æ¨¡å‹ {MODEL_SIZE} ({DEVICE}, {COMPUTE_TYPE})...\")\n    model = WhisperModel(MODEL_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)\n\n    processed = 0\n    total_audio_duration = 0.0\n    total_transcribe_time = 0.0\n    results = []\n\n    for mp3_path in mp3_files:\n        txt_path = mp3_path.with_suffix(\".txt\")\n        if txt_path.exists():\n            duration = get_audio_duration(mp3_path)\n            print(f\"è·³è¿‡: {txt_path.name} å·²å­˜åœ¨ ({duration:.2f}s)\")\n            total_audio_duration += duration\n            continue\n\n        try:\n            text, duration, elapsed = transcribe_audio(mp3_path, model)\n            txt_path.write_text(text, encoding=\"utf-8\")\n\n            total_audio_duration += duration\n            total_transcribe_time += elapsed\n            processed += 1\n\n            rtf = elapsed / duration if duration > 0 else float('inf')\n            print(f\"å®Œæˆ: {mp3_path.name} | æ—¶é•¿ {duration:.2f}s | è€—æ—¶ {elapsed:.2f}s | RTF {rtf:.2f}x\")\n            results.append((mp3_path.name, duration, elapsed, rtf))\n\n        except Exception as e:\n            print(f\"é”™è¯¯è½¬å½• {mp3_path.name}: {e}\", file=sys.stderr)\n\n    # ================== æ±‡æ€»ç»Ÿè®¡ ==================\n    print(\"\\n\" + \"=\" * 60)\n    print(\"è½¬å½•å®Œæˆæ±‡æ€»\")\n    print(\"=\" * 60)\n    print(f\"æˆåŠŸå¤„ç†æ–‡ä»¶æ•°   : {processed}\")\n    print(f\"æ€»éŸ³é¢‘æ—¶é•¿       : {format_time(total_audio_duration)}\")\n    print(f\"æ€»è½¬å½•è€—æ—¶       : {format_time(total_transcribe_time)}\")\n    if total_audio_duration > 0:\n        avg_rtf = total_transcribe_time / total_audio_duration\n        print(f\"å¹³å‡å®æ—¶å€ç‡(RTF): {avg_rtf:.2f}x\")\n    else:\n        print(f\"å¹³å‡å®æ—¶å€ç‡(RTF): N/A\")\n\n    if results:\n        print(f\"\\næ˜ç»†åˆ—è¡¨ï¼š\")\n        print(f\"{'æ–‡ä»¶å':<40} {'éŸ³é¢‘æ—¶é•¿':>10} {'è½¬å½•è€—æ—¶':>10} {'RTF':>8}\")\n        print(\"-\" * 70)\n        for name, dur, ela, rtf in results:\n            print(f\"{name:<40} {dur:10.2f}s {ela:10.2f}s {rtf:8.2f}x\")\n\n    print(\"=\" * 60)\n\n\nif __name__ == \"__main__\":\n    main()",
      "pubDate": "Wed, 12 Nov 2025 04:43:04 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "The Future of Enterprise IT The Enterprise Reasoning Era Has Arrived",
      "link": "https://dev.to/sip_mjb/the-future-of-enterprise-itthe-enterprise-reasoning-era-has-arrived-1778",
      "description": "There is a shift happening in enterprise IT â€” one that won't wait for roadmaps, committees, or comfort zones. For the last decade, digital transformation revolved around workflows. We automated tickets. We integrated systems. We standardized processes. But here's the truth most leaders are only now beginning to confront: Workflows alone are no longer enough.\nDecisions Are the New Bottleneck\nDecisions are the new bottleneck. Reasoning is the new frontier.\nEnter the Enterprise Reasoning Layer â€” the next evolution in how ServiceNow-powered organizations operate, scale, and lead.\nNot automation. Not \"AI add-ons.\" Not more dashboards or scripts.\nA reasoning fabric that learns, evaluates, recommends, and increasingly acts â€” with governance, guardrails, and executive trust built in.\nThe organizations that master this layer will earn an advantage no platform license alone can offer: continuous clarity, continuous momentum, and continuous resilience.\nWhy This Shift Matters Now\nSystems scale faster than decisions\nMade manually\nUntil now.\nAI is not entering the enterprise to replace people. It's entering to amplify intelligence and eliminate cognitive bottlenecks.\nThis isn't AI that does tasks for you. It's AI that helps you reason, act, and operate at the speed modern business demands.\nFrom Workflow Automation to Enterprise Reasoning\nLet's draw the evolution clearly:\nEra Enterprise Focus    Platform Power  Limitation\nWhere incidents don't just get resolved fasterâ€¦ They get prevented.\nWhy ServiceNow Is Built for the Reasoning Future\nInconsistent decision logic\nIt already gives enterprises:\nA single operational backbone\nWhat the Enterprise Reasoning Layer Looks Like\nğŸ§ \nMarkets move faster\nOrganizations that delay reasoning architecture will lag operationally â€” and strategically.\nThe winners will be those who operate their enterprise the way traders operate markets: real-time, informed, confident, adaptive.\nWhat CIOs Should Focus On Right Now\n1\nStop treating AI as a bolt-on\nIncidents anticipate themselves\nThe Role of Partners in This New Chapter\nBut this next shift demands something different:\nStrategic vision\nThey guide technology maturity. They institutionalize intelligence. They ensure control, trust, and scale.\nThey don't just build workflows. They build enterprise advantage.\nYour Platform Already Knows How You Work. Soon, It Will Help You Decide.\nAutomate less manual activity\nIf you lead technology decisions in your organization, ask yourself one question:\nIs your platform just automating work, or is it preparing to reason with you?\nThe enterprises building that layer today will define how industries operate tomorrow.\nFAQ\nIs this replacing IT teams?\nHow is this different from AI-assisted or predictive ITSM?\nDo we need new tools?\nWhere should CIOs begin?\nNext Steps\nAnd the enterprises that embrace it first will lead the next decade of digital performance.\nPartner With MJB Technologies",
      "pubDate": "Wed, 12 Nov 2025 04:42:52 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "Pengalaman visual dan performa",
      "link": "https://dev.to/radenwijayalibcloud/pengalaman-visual-dan-performa-13nm",
      "description": "Teknologi Negative Nimbus Storm Ggplay88 framework teknologi hybrid yang menggabungkan komputasi awan, AI, dan sistem energi dinamis untuk menghasilkan efisiensi maksimal. Berdasarkan penelitian Future Storm Ggplay88 (2024), sistem â€œnegative flow computingâ€ bisa meningkatkan efisiensi hingga 45% dalam arsitektur hybrid cloud.",
      "pubDate": "Wed, 12 Nov 2025 04:34:46 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "Create Your First MCP Tool: The readFile Tool Explained",
      "link": "https://dev.to/ndabene/create-your-first-mcp-tool-the-readfile-tool-explained-3e0h",
      "description": "Hey developers! Nicolas DabÃ¨ne here.\nRemember that feeling when a complex theory clicks into place and your code just works? That's the moment we're chasing today. After setting up our TypeScript environment in previous discussions, it's time to build something truly tangible: your very first Model Context Protocol (MCP) tool. We're going to empower an AI to interact directly with your machine's file system, starting with a simple yet powerful readFile function. This isn't just theory; it's hands-on code that truly operates.\nImagine telling your AI, \"Read me the project_report.md file,\" and it retrieves the content. That interaction becomes possible thanks to the MCP server we're building. Mastering this first tool will open the door to creating a whole suite of custom functionalities for your AI.\nBefore we dive into the code, let's quickly recap what an MCP tool entails. At its core, an MCP tool is essentially a function you expose to an AI. This exposure requires three critical pieces of metadata that help the AI understand and utilize your tool:\n  The tool's name: A unique identifier the AI uses to invoke your tool (e.g., \"readFile\").\n  A clear description: Explains the tool's purpose, guiding the AI on when to use it effectively.\n  The parameters: Defines the input data the tool expects to receive to perform its operation.\nThink of it like providing your function with a comprehensive instruction manual that the AI can read and understand. Simple, right?\nEvery MCP tool we create will adhere to a consistent structure. This skeleton ensures maintainability and clarity, making it easier to scale your toolset. Hereâ€™s a typical layout we'll follow:\n// 1. Interface for input parameters\ninterface ToolParams {\n  // Data the AI sends us\n}\n\n// 2. Interface for the tool's response\ninterface ToolResponse {\n  success: boolean;\n  content?: string;\n  error?: string;\n}\n\n// 3. The asynchronous function that contains the tool's core logic\nasync function myTool(params: ToolParams): Promise<ToolResponse> {\n  // Your business logic goes here\n}\n\n// 4. The tool's formal definition, recognizable by the AI\nexport const myToolDefinition = {\n  name: \"myTool\",\n  description: \"A brief explanation of what my tool achieves\",\n  parameters: {\n    // Detailed description of expected input parameters\n  }\n};\n\nThis four-part schema will serve as our blueprint for constructing robust and AI-friendly tools.\nLet's organize our mcp-server project for a clean and scalable architecture. Run these commands to create our essential directories:\nmkdir -p src/tools\nmkdir -p src/types\n\nThe src/tools folder will house our individual MCP tools, while src/types will store our shared TypeScript interface definitions, ensuring type safety and consistency across the project.\nOur next step is to create the foundational TypeScript interfaces. In src/types/mcp.ts, add the following code:\n// src/types/mcp.ts\n\n// Generic type for tool parameters, allowing for flexible inputs\nexport interface ToolParams {\n  [key: string]: any;\n}\n\n// Standardized structure for a tool's response\nexport interface ToolResponse {\n  success: boolean;\n  content?: string; // Optional: for textual output\n  error?: string;   // Optional: for error messages\n  metadata?: {      // Optional: for additional structured data\n    [key: string]: any;\n  };\n}\n\n// Interface for the formal definition of a tool, as presented to the AI\nexport interface ToolDefinition {\n  name: string;\n  description: string;\n  parameters: {\n    [paramName: string]: {\n      type: string;        // e.g., \"string\", \"number\", \"boolean\"\n      description: string; // Explains the parameter's role\n      required: boolean;   // Indicates if the parameter is mandatory\n    };\n  };\n}\n\n// Specific type for the parameters required by our readFile tool\nexport interface ReadFileParams extends ToolParams {\n  file_path: string;\n}\n\nThese interfaces are invaluable. They provide strong typing, enabling auto-completion and catching potential errors during development, making TypeScript an indispensable ally in this project.\nreadFile Tool\n\n\nNow, for the main event! Let's implement our readFile tool. Create the file src/tools/readFile.ts and populate it with this code:\n// src/tools/readFile.ts\nimport fs from 'fs/promises';\nimport path from 'path';\nimport { ReadFileParams, ToolResponse, ToolDefinition, ToolParams } from '../types/mcp';\n\n/**\n * Reads the content of a text file from the local file system.\n * Includes robust validation and security checks.\n * @param params - Parameters containing the file path and optional encoding.\n * @returns A promise resolving to a ToolResponse with the file content or an error.\n */\nexport async function readFile(params: ReadFileParams): Promise<ToolResponse> {\n  try {\n    // Step 1: Input Validation\n    if (!params.file_path) {\n      return {\n        success: false,\n        error: \"The 'file_path' parameter is required.\"\n      };\n    }\n\n    // Step 2: Security - Resolve Absolute Path\n    // This critical step prevents directory traversal attacks (e.g., '../../etc/passwd').\n    const absolutePath = path.resolve(params.file_path);\n\n    // Step 3: Verify File Existence\n    try {\n      await fs.access(absolutePath);\n    } catch {\n      return {\n        success: false,\n        error: `File not found at path: '${params.file_path}'`\n      };\n    }\n\n    // Step 4: Retrieve File Information\n    const stats = await fs.stat(absolutePath);\n\n    // Step 5: Confirm it's a file, not a directory\n    if (!stats.isFile()) {\n      return {\n        success: false,\n        error: \"The specified path points to a directory, not a file.\"\n      };\n    }\n\n    // Step 6: Enforce Size Limit (Security & Performance)\n    // Prevents accidental loading of excessively large files into memory.\n    const MAX_FILE_SIZE = 10 * 1024 * 1024; // 10 MB limit\n    if (stats.size > MAX_FILE_SIZE) {\n      return {\n        success: false,\n        error: `File size exceeds the maximum allowed (${MAX_FILE_SIZE / (1024 * 1024)} MB).`\n      };\n    }\n\n    // Step 7: Read File Content with specified encoding (defaulting to UTF-8)\n    const encoding: BufferEncoding = (params.encoding || 'utf-8') as BufferEncoding;\n    const content = await fs.readFile(absolutePath, encoding);\n\n    // Step 8: Return Success with Content and Useful Metadata\n    return {\n      success: true,\n      content: content.toString(), // Ensure content is a string\n      metadata: {\n        path: absolutePath,\n        size: stats.size,\n        encoding: encoding,\n        lastModified: stats.mtime.toISOString()\n      }\n    };\n\n  } catch (error: any) {\n    // Step 9: Handle Unexpected Errors Gracefully\n    return {\n      success: false,\n      error: `An unexpected error occurred while reading the file: ${error.message}`\n    };\n  }\n}\n\n/**\n * The formal definition of the 'readFile' tool for the MCP protocol.\n * This is what the AI will \"see\" when it inspects available tools.\n */\nexport const readFileToolDefinition: ToolDefinition = {\n  name: \"readFile\",\n  description: \"Reads the content of a text file from the local file system.\",\n  parameters: {\n    file_path: {\n      type: \"string\",\n      description: \"The absolute or relative path to the file to be read.\",\n      required: true\n    },\n    encoding: {\n      type: \"string\",\n      description: \"The character encoding to use (e.g., 'utf-8', 'ascii', 'base64'). Defaults to 'utf-8'.\",\n      required: false\n    }\n  }\n};\n\nTake a moment to appreciate the thought behind each step:\n  Validation: We always verify that critical parameters are provided.\n  Security: Path resolution protects against malicious attempts to access restricted areas.\n  Existence & Type Checks: We ensure the target exists and is a file, not a directory, to prevent unexpected errors.\n  Size Limits: A practical defense against inadvertently loading massive files.\n  Robust Reading: Handles various encodings for flexibility.\n  Enriched Response: Provides not just content, but valuable metadata.\n  Error Handling: Catches and reports issues cleanly.\nTo manage our growing collection of tools, let's create a central manager. Add the following to src/tools/index.ts:\n// src/tools/index.ts\nimport { ToolDefinition, ToolResponse, ToolParams } from '../types/mcp';\nimport { readFile, readFileToolDefinition } from './readFile'; // Import our first tool\n\n// A registry mapping tool names to their execution functions\nexport const tools = {\n  readFile: readFile,\n  // Add other tools here as you create them\n};\n\n// An array containing the formal definitions of all available tools\nexport const toolDefinitions: ToolDefinition[] = [\n  readFileToolDefinition,\n  // Add other tool definitions here\n];\n\n/**\n * A helper function to dynamically execute a tool by its name.\n * @param toolName - The name of the tool to execute.\n * @param params - The parameters to pass to the tool.\n * @returns A promise resolving to the tool's response.\n */\nexport async function executeTool(toolName: string, params: ToolParams): Promise<ToolResponse> {\n  const tool = tools[toolName as keyof typeof tools]; // Type assertion for dynamic access\n\n  if (!tool) {\n    return {\n      success: false,\n      error: `Error: Tool '${toolName}' not found.`\n    };\n  }\n\n  // Execute the tool function\n  return await tool(params);\n}\n\nThis index.ts file acts as our central hub. As you develop more MCP tools, you'll simply register them here, making them discoverable and executable.\nNow, let's modify src/index.ts to expose our MCP tools via HTTP endpoints using Express:\n// src/index.ts\nimport express, { Request, Response } from 'express';\nimport { toolDefinitions, executeTool } from './tools'; // Import our tool manager\n\nconst app = express();\nconst PORT = 3000;\n\n// Middleware to parse JSON request bodies\napp.use(express.json());\n\n// Basic health check route\napp.get('/', (req: Request, res: Response) => {\n  res.json({\n    message: 'MCP Server is up and running!',\n    version: '1.0.0'\n  });\n});\n\n// Endpoint for AI to discover available tools (the \"tool menu\")\napp.get('/tools', (req: Request, res: Response) => {\n  res.json({\n    success: true,\n    tools: toolDefinitions\n  });\n});\n\n// Endpoint for AI to execute a specific tool\napp.post('/tools/:toolName', async (req: Request, res: Response) => {\n  const { toolName } = req.params;\n  const params = req.body; // Parameters sent by the AI\n\n  try {\n    const result = await executeTool(toolName, params);\n    res.json(result); // Send the tool's response back\n  } catch (error: any) {\n    // Catch any unexpected server-side errors during tool execution\n    res.status(500).json({\n      success: false,\n      error: `Server-side error during tool execution: ${error.message}`\n    });\n  }\n});\n\n// Start the server\napp.listen(PORT, () => {\n  console.log(`âœ… MCP Server launched on http://localhost:${PORT}`);\n  console.log(`ğŸ“‹ Discover tools: http://localhost:${PORT}/tools`);\n});\n\nOur Express server now exposes two critical endpoints:\n  GET /tools: Provides a list of all available MCP tools and their definitions. This is how an AI learns what it can do.\n  POST /tools/:toolName: Allows an AI to invoke a specific tool, passing necessary parameters in the request body.\nLet's put our readFile tool to the test. First, create a simple test file in your project's root:\necho \"This is a test file for the MCP server. Hello, AI!\" > test.txt\n\nNow, launch your MCP server:\nnpm run dev\n\nYou should see output similar to:\nâœ… MCP Server launched on http://localhost:3000\nğŸ“‹ Discover tools: http://localhost:3000/tools\n\nOpen a new terminal and query your server's /tools endpoint:\ncurl http://localhost:3000/tools\n\nExpected response:\n{\n  \"success\": true,\n  \"tools\": [\n    {\n      \"name\": \"readFile\",\n      \"description\": \"Reads the content of a text file from the local file system.\",\n      \"parameters\": {\n        \"file_path\": {\n          \"type\": \"string\",\n          \"description\": \"The absolute or relative path to the file to be read.\",\n          \"required\": true\n        },\n        \"encoding\": {\n          \"type\": \"string\",\n          \"description\": \"The character encoding to use (e.g., 'utf-8', 'ascii', 'base64'). Defaults to 'utf-8'.\",\n          \"required\": false\n        }\n      }\n    }\n  ]\n}\n\nFantastic! Your AI can now discover the readFile tool and understand its capabilities.\nreadFile Tool\n\n\nLet's use our readFile tool to retrieve the content of test.txt:\ncurl -X POST http://localhost:3000/tools/readFile \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"file_path\": \"test.txt\"}'\n\nExpected response (paths and dates will vary):\n{\n  \"success\": true,\n  \"content\": \"This is a test file for the MCP server. Hello, AI!\\n\",\n  \"metadata\": {\n    \"path\": \"/absolute/path/to/your/project/test.txt\",\n    \"size\": 47,\n    \"encoding\": \"utf-8\",\n    \"lastModified\": \"2023-10-27T14:30:00.000Z\"\n  }\n}\n\nIt's alive! Your MCP server successfully read the file.\nNow, let's test with a file that doesn't exist:\ncurl -X POST http://localhost:3000/tools/readFile \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"file_path\": \"nonexistent_file.txt\"}'\n\nResponse:\n{\n  \"success\": false,\n  \"error\": \"File not found at path: 'nonexistent_file.txt'\"\n}\n\nExcellent! Our error handling is working as expected.\nlistFiles Tool\n\n\nNow that you're comfortable creating an MCP tool, let's quickly build another one: listFiles. This tool will allow the AI to inspect directory contents.\nCreate src/tools/listFiles.ts:\n// src/tools/listFiles.ts\nimport fs from 'fs/promises';\nimport path from 'path';\nimport { ToolParams, ToolResponse, ToolDefinition } from '../types/mcp';\n\n// Specific type for listFiles parameters\nexport interface ListFilesParams extends ToolParams {\n  directory_path: string;\n}\n\n/**\n * Lists files and directories within a specified path.\n * @param params - Parameters containing the directory path.\n * @returns A promise resolving to a ToolResponse with directory contents or an error.\n */\nexport async function listFiles(params: ListFilesParams): Promise<ToolResponse> {\n  try {\n    if (!params.directory_path) {\n      return {\n        success: false,\n        error: \"The 'directory_path' parameter is required.\"\n      };\n    }\n\n    const absolutePath = path.resolve(params.directory_path);\n\n    // Verify it's a directory\n    let stats;\n    try {\n      stats = await fs.stat(absolutePath);\n    } catch (e: any) {\n      if (e.code === 'ENOENT') {\n        return { success: false, error: `Directory not found at path: '${params.directory_path}'` };\n      }\n      throw e; // Re-throw other errors\n    }\n\n    if (!stats.isDirectory()) {\n      return {\n        success: false,\n        error: \"The specified path is not a directory.\"\n      };\n    }\n\n    // Read directory content\n    const files = await fs.readdir(absolutePath);\n\n    // Get details for each item\n    const filesWithDetails = await Promise.all(\n      files.map(async (file) => {\n        const itemPath = path.join(absolutePath, file);\n        const itemStats = await fs.stat(itemPath);\n\n        return {\n          name: file,\n          type: itemStats.isDirectory() ? 'directory' : 'file',\n          size: itemStats.size,\n          lastModified: itemStats.mtime.toISOString()\n        };\n      })\n    );\n\n    return {\n      success: true,\n      content: JSON.stringify(filesWithDetails, null, 2), // Pretty-print JSON\n      metadata: {\n        path: absolutePath,\n        count: filesWithDetails.length\n      }\n    };\n\n  } catch (error: any) {\n    return {\n      success: false,\n      error: `Error listing directory contents: ${error.message}`\n    };\n  }\n}\n\n/**\n * The formal definition of the 'listFiles' tool for the MCP protocol.\n */\nexport const listFilesToolDefinition: ToolDefinition = {\n  name: \"listFiles\",\n  description: \"Lists files and subdirectories within a specified directory, providing their type, size, and last modification date.\",\n  parameters: {\n    directory_path: {\n      type: \"string\",\n      description: \"The absolute or relative path to the directory whose contents are to be listed.\",\n      required: true\n    }\n  }\n};\n\nNow, integrate this new tool into our src/tools/index.ts manager:\n// src/tools/index.ts\nimport { ToolDefinition, ToolResponse, ToolParams } from '../types/mcp';\nimport { readFile, readFileToolDefinition } from './readFile';\nimport { listFiles, listFilesToolDefinition } from './listFiles'; // Import the new tool\n\nexport const tools = {\n  readFile: readFile,\n  listFiles: listFiles // Add listFiles to the registry\n};\n\nexport const toolDefinitions: ToolDefinition[] = [\n  readFileToolDefinition,\n  listFilesToolDefinition // Add listFiles's definition\n];\n\nexport async function executeTool(toolName: string, params: ToolParams): Promise<ToolResponse> {\n  const tool = tools[toolName as keyof typeof tools];\n\n  if (!tool) {\n    return {\n      success: false,\n      error: `Error: Tool '${toolName}' not found.`\n    };\n  }\n\n  return await tool(params);\n}\n\nRestart your server (npm run dev) and test tool discovery again:\ncurl http://localhost:3000/tools\n\nYou'll now see both readFile and listFiles proudly listed!\nAs you expand your MCP tool capabilities, security becomes paramount. Here are critical best practices:\nNever assume inputs are benign. Always validate data types, formats, lengths, and acceptable values. This is your first line of defense against malformed or malicious requests.\nBy default, Node.js can access your entire file system. For AI-driven tools, you must restrict this. Implement whitelisting for allowed directories:\nconst ALLOWED_DIRECTORIES = [\n  path.resolve('/home/user/my-project-data'), // Example user data\n  path.resolve(process.cwd()),                // Current working directory\n];\n\nfunction isPathAllowed(filePath: string): boolean {\n  const absolute = path.resolve(filePath);\n  // Ensure the resolved path starts with one of the allowed directories\n  return ALLOWED_DIRECTORIES.some(dir => absolute.startsWith(dir + path.sep) || absolute === dir);\n}\n// Integrate this check into your readFile and listFiles functions\n\nPrevent resource exhaustion by limiting:\n  File sizes: As shown in readFile, avoid loading huge files.\n  Number of results: For directory listings or searches.\n  Recursion depth: If you implement recursive tools, prevent infinite loops.\nKeep detailed logs of which tools are executed, by whom (if authenticated), with what parameters, and the outcome. This is crucial for auditing, debugging, and identifying suspicious activity.\nconsole.log(`[${new Date().toISOString()}] Tool Executed: ${toolName}, Params: ${JSON.stringify(params)}`);\n\nCongratulations, developer! You've just created and integrated your first functional MCP tools. You've gone beyond theory to:\n  Structure a robust MCP tool using TypeScript.\n  Manage parameters and craft meaningful responses.\n  Implement crucial input validation and error handling.\n  Expose your tools via a clean REST API.\n  Effectively test your tools using curl.\n  Establish a pattern for creating and registering multiple tools.\nThis is a significant step towards building truly intelligent agents that can interact with your digital environment. What kind of tools are you excited to build next? Perhaps one to search file contents, or analyze structured data, or even automate deployment tasks? The possibilities for empowering your AI are now limitless.\nLooking forward to hearing about your creations!\nNicolas DabÃ¨ne\n\n\n  \n  \n  AI #TypeScript #Nodejs",
      "pubDate": "Wed, 12 Nov 2025 04:33:38 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "NDC Conferences: The future & challenges of cloud - Anders Lybecker - NDC Copenhagen 2025",
      "link": "https://dev.to/scale_youtube/ndc-conferences-the-future-challenges-of-cloud-anders-lybecker-ndc-copenhagen-2025-32g5",
      "description": "The Future & Challenges of Cloud\n\n\nAnders Lybeckerâ€™s NDC Copenhagen session dives headfirst into the next frontier of cloud computing. He unpacks hot topics like AI-native clouds, serverless 2.0 and composable architectures, while flagging real-world pain pointsâ€”think multi-cloud complexity, vendor lock-in and the tug-of-war between cost and performance. He also highlights data gravity and the push for standardization as key forces shaping your cloud strategy.\nSecurity and compliance get a deep dive too, from AI-powered cyberattacks and zero-trust models to the rise of Cloud Security Posture Management (CSPM) tools. Rounding things off, Anders peers into the crystal ball of AI & cloud synergyâ€”hardware breakthroughs, higher-level managed services and the boom in no-code, low-code and AI-assisted development platforms. Itâ€™s a must-see roadmap for anyone wrestling with todayâ€™s cloud chaos and tomorrowâ€™s innovations.\nWatch on YouTube",
      "pubDate": "Wed, 12 Nov 2025 04:32:01 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "ğŸš€ Why Programming Knowledge Still Matters in the Age of AI Development Tools",
      "link": "https://dev.to/harukin399/why-programming-knowledge-still-matters-in-the-age-of-ai-development-tools-11b9",
      "description": "Recently, weâ€™ve seen an explosion of AI-powered tools that claim to build entire apps for you â€” from landing pages and chatbots to full-stack projects.\nBut hereâ€™s the truth â€” even with these incredible tools, programming knowledge still matters.\nğŸ§  1. Understanding What AI Builds\nAI tools can generate impressive code quickly, but they donâ€™t always understand why theyâ€™re building something in a particular way.\nEvaluate if the generated \ncode follows best practices\nIdentify potential performance or security issues\nDebug or extend the generated features\nAI can produce the code, but only a developer can truly understand it.\nâš™ï¸ 2. Customization Always Requires Logic\nEvery real-world project eventually needs something unique â€” a special user flow, a custom API integration, or an unconventional UI behavior.\nKnowing how to code lets you:\nModify and optimize AI-generated logic\nExtend functionality beyond templates\nIntegrate multiple systems cleanly\nAI gets you started fast, but your programming skill helps you finish strong.\nğŸ” 3. Debugging and Maintenance Donâ€™t Disappear\nAI tools might create a working prototype, but once something breaks (and it will), you need to know how to fix it.\nErrors occur\nAPIs change\nRequirements evolve\nThink of AI as an assistant â€” not a replacement.\nğŸ’¡ 4. Developers Who Use AI Are the Future\nThe real power lies in combining AI and human expertise.\nğŸ”š In Short\nAI can generate projects, but programming knowledge is what makes you capable of:\nUnderstanding\nCustomizing\nMaintaining\nInnovating\nAI is not replacing developers â€” itâ€™s amplifying those who already know how to build.\nWhat do you think?\nLetâ€™s discuss ğŸ‘‡",
      "pubDate": "Wed, 12 Nov 2025 04:31:34 +0000",
      "source": "Dev.to AI",
      "sourceUrl": "https://dev.to/feed/tag/ai",
      "credibility": 0.8,
      "category": "developer"
    },
    {
      "title": "Introducing agent-to-agent protocol support in Amazon Bedrock AgentCore Runtime",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-agent-to-agent-protocol-support-in-amazon-bedrock-agentcore-runtime/",
      "description": "In this post, we demonstrate how you can use the A2A protocol for AI agents built with different frameworks to collaborate seamlessly. You'll learn how to deploy A2A servers on AgentCore Runtime, configure agent discovery and authentication, and build a real-world multi-agent system for incident response. We'll cover the complete A2A request lifecycle, from agent card discovery to task delegation, showing how standardized protocols eliminate the complexity of multi-agent coordination.",
      "pubDate": "Tue, 11 Nov 2025 21:32:31 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Powering enterprise search with the Cohere Embed 4 multimodal embeddings model in Amazon Bedrock",
      "link": "https://aws.amazon.com/blogs/machine-learning/powering-enterprise-search-with-the-cohere-embed-4-multimodal-embeddings-model-in-amazon-bedrock/",
      "description": "The Cohere Embed 4 multimodal embeddings model is now available as a fully managed, serverless option in Amazon Bedrock. In this post, we dive into the benefits and unique capabilities of Embed 4 for enterprise search use cases. Weâ€™ll show you how to quickly get started using Embed 4 on Amazon Bedrock, taking advantage of integrations with Strands Agents, S3 Vectors, and Amazon Bedrock AgentCore to build powerful agentic retrieval-augmented generation (RAG) workflows.",
      "pubDate": "Tue, 11 Nov 2025 20:59:54 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "A guide to building AI agents in GxP environments",
      "link": "https://aws.amazon.com/blogs/machine-learning/a-guide-to-building-ai-agents-in-gxp-environments/",
      "description": "The regulatory landscape for GxP compliance is evolving to address the unique characteristics of AI. Traditional Computer System Validation (CSV) approaches, often with uniform validation strategies, are being supplemented by Computer Software Assurance (CSA) frameworks that emphasize flexible risk-based validation methods tailored to each system's actual impact and complexity (FDA latest guidance). In this post, we cover a risk-based implementation, practical implementation considerations across different risk levels, the AWS shared responsibility model for compliance, and concrete examples of risk mitigation strategies.",
      "pubDate": "Tue, 11 Nov 2025 20:33:09 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Multi-Agent collaboration patterns with Strands Agents and Amazon Nova",
      "link": "https://aws.amazon.com/blogs/machine-learning/multi-agent-collaboration-patterns-with-strands-agents-and-amazon-nova/",
      "description": "In this post, we explore four key collaboration patterns for multi-agent, multimodal AI systems â€“ Agents as Tools, Swarms Agents, Agent Graphs, and Agent Workflows â€“ and discuss when and how to apply each using the open-source AWS Strands Agents SDK with Amazon Nova models.",
      "pubDate": "Tue, 11 Nov 2025 20:28:14 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "JetBrains Plugin Developer Conf 2025 Recordings Are Now Live",
      "link": "https://blog.jetbrains.com/platform/2025/11/jetbrains-plugin-developer-conf-2025-recordings-are-now-live/",
      "description": "On November 5, 2025, we hosted the second annual JetBrains Plugin Developer Conf, a day dedicated to everything related to building, publishing, and growing plugins for JetBrains IDEs.Thank you to everyone who joined us live and helped make this yearâ€™s event even more interactive and inspiring than before! If you missed the live stream or [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 17:51:08 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "C# 14 Language Features in ReSharper and Rider 2025.3",
      "link": "https://blog.jetbrains.com/dotnet/2025/11/11/csharp-14-language-features-in-resharper-and-rider-2025-3/",
      "description": "Last year marked the first time we shipped ReSharper and Rider side by side with the official .NET SDK release â€“ and weâ€™re happy to announce that weâ€™ve done it again with the 2025.3 release! Download Rider 2025.3 Download ReSharper 2025.3 With .NET 10 and C# 14, both ReSharper and Rider are ready on day [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 15:49:55 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Whatâ€™s Been Fixed in Rider 2025.3",
      "link": "https://blog.jetbrains.com/dotnet/2025/11/11/what-s-been-fixed-in-rider-2025-3/",
      "description": "Each release of JetBrains Rider is shaped by an ongoing conversation between our team and our users. Your feedback, bug reports, and upvotes complement our internal QA processes and performance tracking, helping us understand how issues manifest across diverse environments and project setups. This collaboration allows us to prioritize the fixes that have the greatest [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 15:49:14 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "ReSharper C++ 2025.3: C++26 Language Support, Faster Unreal Engine Startup, and Visual Studio 2026 Compatibility",
      "link": "https://blog.jetbrains.com/rscpp/2025/11/11/resharper-cpp-2025-3/",
      "description": "Weâ€™re excited to announce that ReSharper C++ 2025.3 is here, bringing major language updates, performance improvements, and a refined UI in the upcoming Microsoft Visual Studio 2026 release. This version advances C++26 support with new language features, improves constexpr evaluation, and offers a refined Out-of-Process mode for smoother, more responsive performance. Unreal Engine developers will [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 15:48:50 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "ReSharper 2025.3: Day-One C# 14 Support, Visual Studio 2026 Compatibility, and Major Performance Gains",
      "link": "https://blog.jetbrains.com/dotnet/2025/11/11/resharper-2025-3-day-one-csharp-14-support-visual-studio-2026-compatible/",
      "description": "Weâ€™re pleased to announce the release of ReSharper 2025.3 in sync with .NET 10, continuing our tradition of releases that deliver day-one support for the newest C# language features. This version brings comprehensive C# 14 coverage, including extension members, extension operators, and user-defined compound assignment operators â€“ all ready to use as soon as you [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 15:48:34 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Rider 2025.3: Day-One Support for .NET 10 and C# 14, a New Default UI, and Faster Startup",
      "link": "https://blog.jetbrains.com/dotnet/2025/11/11/rider-2025-3-day-one-support-for-dotnet-10/",
      "description": "Rider 2025.3 arrives alongside the .NET 10 SDK, continuing our commitment to day-one support for the latest .NET and C# features. This release brings full compatibility with .NET 10 and comprehensive support for C# 14, including extension members, extension operators, and user-defined compound assignment operators â€“ all ready to use from the moment you upgrade [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 15:48:17 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "AI code means more critical thinking, not less",
      "link": "https://stackoverflow.blog/2025/11/11/ai-code-means-more-critical-thinking-not-less/",
      "description": "Ryan is joined by Secure Code Warriorâ€™s co-founder and CTO Matias Madou to discuss the  implications of LLMsâ€™ variability on code security, the future of developer training as AI coding assistants become more popular, and the importance of critical thinkingâ€”especially for junior developersâ€”in the age of AI.",
      "pubDate": "Tue, 11 Nov 2025 08:40:00 GMT",
      "source": "Stack Overflow Blog",
      "sourceUrl": "https://stackoverflow.blog/feed/",
      "credibility": 0.85,
      "category": "tech_news"
    },
    {
      "title": "Building AI Agents in Kotlin â€“ Part 1: A Minimal Coding Agent",
      "link": "https://blog.jetbrains.com/ai/2025/11/building-ai-agents-in-kotlin-part-1-a-minimal-coding-agent/",
      "description": "Building agents is weird. Youâ€™re not writing code that does things. Youâ€™re writing code that gives an LLM the ability to do things, and the LLM decides what to do. What is an agent? An agent is an LLM that calls your functions in a loop until it decides the task is complete. That shift [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 08:35:38 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "JetBrains and DMCC AI Centre Announce Strategic Partnership to Accelerate AI Innovation",
      "link": "https://blog.jetbrains.com/blog/2025/11/11/jetbrains-and-dmcc-ai-centre-announce-strategic-partnership-to-accelerate-ai-innovation/",
      "description": "JetBrains and the DMCC AI Centre, a premier hub for artificial intelligence (AI) and innovation in the UAE, have announced a strategic collaboration to advance the growth of AI-driven innovation, entrepreneurship, and technical excellence within Dubaiâ€™s technology ecosystem. The agreement marks a key step in JetBrainsâ€™ rapid expansion across the MENA region, as its local [â€¦]",
      "pubDate": "Tue, 11 Nov 2025 07:00:00 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Fine-tune VLMs for multipage document-to-JSON with SageMaker AI and SWIFT",
      "link": "https://aws.amazon.com/blogs/machine-learning/fine-tune-vlms-for-multipage-document-to-json-with-sagemaker-ai-and-swift/",
      "description": "In this post, we demonstrate that fine-tuning VLMs provides a powerful and flexible approach to automate and significantly enhance document understanding capabilities. We also demonstrate that using focused fine-tuning allows smaller, multi-modal models to compete effectively with much larger counterparts (98% accuracy with Qwen2.5 VL 3B).",
      "pubDate": "Mon, 10 Nov 2025 19:59:01 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "How Clario automates clinical research analysis using generative AI on AWS",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-clario-automates-clinical-research-analysis-using-generative-ai-on-aws/",
      "description": "In this post, we demonstrate how Clario has used Amazon Bedrock and other AWS services to build an AI-powered solution that automates and improves the analysis of COA interviews.",
      "pubDate": "Mon, 10 Nov 2025 18:13:47 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Rust vs. Python: Finding the right balance between speed and simplicity",
      "link": "https://blog.jetbrains.com/rust/2025/11/10/rust-vs-python-finding-the-right-balance-between-speed-and-simplicity/",
      "description": "This blog post was brought to you by Damaso Sanoja, draft.dev. Deciding whether to use Python or Rust isnâ€™t just a syntax choice; itâ€™s a career bet. According to the StackOverflow Developer Survey, Python dominates in accessibility, with 66.4% of people learning to code choosing it as their entry point. Python usage skyrocketed from 32% [â€¦]",
      "pubDate": "Mon, 10 Nov 2025 12:02:48 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "The Go Ecosystem in 2025: Key Trends in Frameworks, Tools, and Developer Practices",
      "link": "https://blog.jetbrains.com/go/2025/11/10/go-language-trends-ecosystem-2025/",
      "description": "Go turns 16 this year. To celebrate this milestone, we have taken a closer look at the latest Developer Ecosystem Survey results and examined the evolution of the Go ecosystem over the past five years. According to JetBrains Data Playground, 2.2 million professional developers use Go as their primary programming language â€“ twice as many [â€¦]",
      "pubDate": "Mon, 10 Nov 2025 09:24:35 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Democratizing AI: How Thomson Reuters Open Arena supports no-code AI for every professional with Amazon Bedrock",
      "link": "https://aws.amazon.com/blogs/machine-learning/democratizing-ai-how-thomson-reuters-open-arena-supports-no-code-ai-for-every-professional-with-amazon-bedrock/",
      "description": "In this blog post, we explore how TR addressed key business use cases with Open Arena, a highly scalable and flexible no-code AI solution powered by Amazon Bedrock and other AWS services such as Amazon OpenSearch Service, Amazon Simple Storage Service (Amazon S3), Amazon DynamoDB, and AWS Lambda. We'll explain how TR used AWS services to build this solution, including how the architecture was designed, the use cases it solves, and the business profiles that use it.",
      "pubDate": "Fri, 07 Nov 2025 21:51:22 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "Introducing structured output for Custom Model Import in Amazon Bedrock",
      "link": "https://aws.amazon.com/blogs/machine-learning/introducing-structured-output-for-custom-model-import-in-amazon-bedrock/",
      "description": "Today, we are excited to announce the addition of structured output to Custom Model Import. Structured output constrains a model's generation process in real time so that every token it produces conforms to a schema you define. Rather than relying on prompt-engineering tricks or brittle post-processing scripts, you can now generate structured outputs directly at inference time.",
      "pubDate": "Fri, 07 Nov 2025 18:53:55 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "What 986 million code pushes say about the developer workflow in 2025",
      "link": "https://github.blog/news-insights/octoverse/what-986-million-code-pushes-say-about-the-developer-workflow-in-2025/",
      "description": "Nearly a billion commits later, the way we ship code has changed for good. Hereâ€™s what the 2025 Octoverse data says about how devs really work now.\nThe post What 986 million code pushes say about the developer workflow in 2025 appeared first on The GitHub Blog.",
      "pubDate": "Fri, 07 Nov 2025 16:00:00 +0000",
      "source": "GitHub Blog",
      "sourceUrl": "https://github.blog/feed/",
      "credibility": 0.95,
      "category": "company_official"
    },
    {
      "title": "Revealing the unknown unknowns in your software",
      "link": "https://stackoverflow.blog/2025/11/07/revealing-the-unknown-unknowns-in-your-software/",
      "description": "Ryan welcomes Nic Benders to discuss the complexity and abstraction crisis in software development, the importance of going beyond observability into understandability, and demystifying AI's opacity for understanding and control.",
      "pubDate": "Fri, 07 Nov 2025 08:40:00 GMT",
      "source": "Stack Overflow Blog",
      "sourceUrl": "https://stackoverflow.blog/feed/",
      "credibility": 0.85,
      "category": "tech_news"
    },
    {
      "title": "GitHub Copilot CLI 101: How to use GitHub Copilot from the command line",
      "link": "https://github.blog/ai-and-ml/github-copilot-cli-101-how-to-use-github-copilot-from-the-command-line/",
      "description": "Curious about using GitHub Copilot in your terminal? Here's our guide to GitHub Copilot CLI, including a starter kit with the best prompts for a wide range of use cases.\nThe post GitHub Copilot CLI 101: How to use GitHub Copilot from the command line appeared first on The GitHub Blog.",
      "pubDate": "Thu, 06 Nov 2025 20:30:00 +0000",
      "source": "GitHub Blog",
      "sourceUrl": "https://github.blog/feed/",
      "credibility": 0.95,
      "category": "company_official"
    },
    {
      "title": "Transform your MCP architecture: Unite MCP servers through AgentCore Gateway",
      "link": "https://aws.amazon.com/blogs/machine-learning/transform-your-mcp-architecture-unite-mcp-servers-through-agentcore-gateway/",
      "description": "Earlier this year, we introduced Amazon Bedrock AgentCore Gateway, a fully managed service that serves as a centralized MCP tool server, providing a unified interface where agents can discover, access, and invoke tools. Today, we're extending support for existing MCP servers as a new target type in AgentCore Gateway. With this capability, you can group multiple task-specific MCP servers aligned to agent goals behind a single, manageable MCP gateway interface. This reduces the operational complexity of maintaining separate gateways, while providing the same centralized tool and authentication management that existed for REST APIs and AWS Lambda functions.",
      "pubDate": "Thu, 06 Nov 2025 17:43:23 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "TypeScriptâ€™s rise in the AI era: Insights from Lead Architect, Anders Hejlsberg",
      "link": "https://github.blog/developer-skills/programming-languages-and-frameworks/typescripts-rise-in-the-ai-era-insights-from-lead-architect-anders-hejlsberg/",
      "description": "TypeScript just became the most-used language on GitHub. Hereâ€™s why, according to its creator.\nThe post TypeScriptâ€™s rise in the AI era: Insights from Lead Architect, Anders Hejlsberg appeared first on The GitHub Blog.",
      "pubDate": "Thu, 06 Nov 2025 17:00:00 +0000",
      "source": "GitHub Blog",
      "sourceUrl": "https://github.blog/feed/",
      "credibility": 0.95,
      "category": "company_official"
    },
    {
      "title": "How Amazon Search increased ML training twofold using AWS Batch for Amazon SageMaker Training jobs",
      "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-search-increased-ml-training-twofold-using-aws-batch-for-amazon-sagemaker-training-jobs/",
      "description": "In this post, we show you how Amazon Search optimized GPU instance utilization by leveraging AWS Batch for SageMaker Training jobs. This managed solution enabled us to orchestrate machine learning (ML) training workloads on GPU-accelerated instance families like P5, P4, and others. We will also provide a step-by-step walkthrough of the use case implementation.",
      "pubDate": "Wed, 05 Nov 2025 17:15:35 +0000",
      "source": "AWS Machine Learning Blog",
      "sourceUrl": "https://aws.amazon.com/blogs/machine-learning/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "GitHub Copilot tutorial: How to build, test, review, and ship code faster (with real prompts)",
      "link": "https://github.blog/ai-and-ml/github-copilot/a-developers-guide-to-writing-debugging-reviewing-and-shipping-code-faster-with-github-copilot/",
      "description": "How GitHub Copilot works todayâ€”including mission controlâ€”and how to get the most out of it. Hereâ€™s what you need to know.\nThe post GitHub Copilot tutorial: How to build, test, review, and ship code faster (with real prompts) appeared first on The GitHub Blog.",
      "pubDate": "Wed, 05 Nov 2025 17:00:00 +0000",
      "source": "GitHub Blog",
      "sourceUrl": "https://github.blog/feed/",
      "credibility": 0.95,
      "category": "company_official"
    },
    {
      "title": "The AI ick",
      "link": "https://stackoverflow.blog/2025/11/05/the-ai-ick/",
      "description": "How we feel about AI-generated content, what AI detectors tell us, and why human creativity matters. Also, what is art?",
      "pubDate": "Wed, 05 Nov 2025 17:00:00 GMT",
      "source": "Stack Overflow Blog",
      "sourceUrl": "https://stackoverflow.blog/feed/",
      "credibility": 0.85,
      "category": "tech_news"
    },
    {
      "title": "The Rider 2025.3 Release Candidate Is Now Available",
      "link": "https://blog.jetbrains.com/dotnet/2025/11/05/the-rider-2025-3-release-candidate/",
      "description": "The next big release for Rider is just around the corner! If youâ€™re eager to get a sneak peek, you can download the Release Candidate version of Rider 2025.3 from our website right now.Â  Here are the feature highlights of the Rider 2025.3 RC build: If you encounter any issues when using the Rider 2025.3 [â€¦]",
      "pubDate": "Wed, 05 Nov 2025 16:30:53 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    },
    {
      "title": "The ReSharper, .NET Tools, and ReSharper C++ 2025.3 Release Candidates Are Now Available",
      "link": "https://blog.jetbrains.com/dotnet/2025/11/05/the-resharper-dotnet-tools-2025-3-release-candidate/",
      "description": "Get a preview of all the latest features and improvements set to be shipped with the next major ReSharper by downloading the Release Candidate builds that have just landed. The ReSharper 2025.3 Release Candidate For the full list of changes included in this build, please refer to the issue tracker.Â  dotTrace, dotMemory, dotCover and dotPeek [â€¦]",
      "pubDate": "Wed, 05 Nov 2025 16:30:45 +0000",
      "source": "JetBrains Blog",
      "sourceUrl": "https://blog.jetbrains.com/feed/",
      "credibility": 0.9,
      "category": "company_blog"
    }
  ],
  "generative_ai": [],
  "ai_chips": [],
  "quantum_computing": [],
  "robotics": [],
  "tech_general": [
    {
      "title": "Be a Force for Good On Giving Tuesday",
      "link": "https://spectrum.ieee.org/ieee-giving-tuesday-2025",
      "description": "Giving Tuesday, being held on 2 December this year, is a day globally dedicated to generosity and empowering individuals and organizations to transform peopleâ€™s lives and communities. For this yearâ€™s event, IEEE and the IEEE Foundation invite members to invest in the organizationâ€™s charitable programs. The programs aim to inspire the next generation of engineers, provide sustainable energy to those in need, assist in emergency response efforts, and more.\nThis Giving Tuesday, members have the opportunity to help amplify the technological breakthroughs and innovative programs that change lives globally.\nDouble your impact\nThe initial US $75,000 donated to the Giving Tuesday campaign will be matched by the IEEE Foundation, dollar for dollar, up to $170,000.\nDonors can direct their gift to the IEEE program they feel most connected to, or they can choose to direct their donation to the IEEE Foundation for efforts that:\n\nIlluminate the possibilities of technology to address global challenges.\nEducate the next generation of innovators and engineers.\nEngage a wider audience to appreciate the impact of engineering.\nEnergize innovation by celebrating excellence.\nShape the destiny of the next generation.\n\nHelp shine a light on your favorite program\nDonating money is not the only way to make an impact on IEEEâ€™s Giving Tuesday. Here are some other opportunities.\n\nBecome a community fundraiser and help promote your favorite IEEE philanthropic program or the IEEE Foundation to your network by creating a personalized page on the IEEE Foundation website. Once your page is set up, you can share it on your social media profiles and email it to your friends, family, and professional contacts.\nShare, like, and comment on Giving Tuesday posts on Facebook and LinkedIn leading up to and on the day.\nPost an #Unselfie photoâ€”a picture of yourself accompanied by why you support IEEEâ€™s philanthropic programsâ€”on social media using the hashtags #IEEEFoundation and #IEEEGivingTuesday. The Foundation provides a tool kit with social media templates and fundraising resources on its website.\n\nFor updates, check the IEEE Foundation Giving Tuesday web page and follow the Foundation on Facebook and LinkedIn.\nThis article was updated on 11 November 2025.",
      "pubDate": "Tue, 11 Nov 2025 19:00:03 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Cradle of humanity is still revealing new insights about our origins",
      "link": "https://www.newscientist.com/article/2503899-cradle-of-humanity-is-still-revealing-new-insights-about-our-origins/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The Omo-Turkana basin in Africa is home to a treasure trove of ancient human fossils and tools that span 300,000 years â€“ today it is still yielding new discoveries about our species",
      "pubDate": "Tue, 11 Nov 2025 18:00:24 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "At-home hypnosis relieves menopausal hot flushes",
      "link": "https://www.newscientist.com/article/2503873-at-home-hypnosis-relieves-menopausal-hot-flushes/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Hot flushes could be relieved by listening to recordings that induce hypnosis from home, rather than having to venture to a clinic",
      "pubDate": "Tue, 11 Nov 2025 17:25:39 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Women have supercharged immune systems and we now know why",
      "link": "https://www.newscientist.com/article/2501447-women-have-supercharged-immune-systems-and-we-now-know-why/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Being born with two X chromosomes brings a host of health benefits, and recognising this could lead to personalised medical treatments for men and wome",
      "pubDate": "Tue, 11 Nov 2025 16:00:38 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Static electricity can remove frost from windows using little energy",
      "link": "https://www.newscientist.com/article/2503870-static-electricity-can-remove-frost-from-windows-using-little-energy/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "High-voltage copper plates can remove up to three-quarters of frost from a surface, while using much less energy than conventional heating",
      "pubDate": "Tue, 11 Nov 2025 15:23:54 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Odds of asteroid 2024 YR4 hitting the moon may rise to 30 per cent",
      "link": "https://www.newscientist.com/article/2503607-odds-of-asteroid-2024-yr4-hitting-the-moon-may-rise-to-30-per-cent/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "In February, the James Webb Space Telescope will briefly be able to observe asteroid 2024 YR4, which currently has a 4 per cent chance of hitting the moon in 2032. Depending on what it sees, the odds of collision could drastically increase",
      "pubDate": "Tue, 11 Nov 2025 14:00:32 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "The Download: surviving extreme temperatures, and the big whale-wind turbine conspiracy",
      "link": "https://www.technologyreview.com/2025/11/11/1127866/the-download-surviving-extreme-temperatures-and-the-big-whale-wind-turbine-conspiracy/",
      "description": "This is todayâ€™s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of whatâ€™s going on in the world of technology. The quest to find out how our bodies react to extreme temperatures Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed toâ€¦",
      "pubDate": "Tue, 11 Nov 2025 13:10:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "The biggest controversy in maths could be settled by a computer",
      "link": "https://www.newscientist.com/article/2503500-the-biggest-controversy-in-maths-could-be-settled-by-a-computer/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "For over a decade, mathematicians have failed to agree whether a 500-page proof is actually correct. Now, translating the proof into a computer-readable form may finally settle the matter",
      "pubDate": "Tue, 11 Nov 2025 12:00:12 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Caves carved by water on Mars may hold signs of past life",
      "link": "https://www.newscientist.com/article/2503049-caves-carved-by-water-on-mars-may-hold-signs-of-past-life/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Eight possible cave openings found on the Martian surface look to have once had ancient streams flowing into them, suggesting they are promising places to look for evidence of life",
      "pubDate": "Tue, 11 Nov 2025 08:00:45 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "The State of AI: Energy is king, and the US is falling behind",
      "link": "https://www.technologyreview.com/2025/11/10/1126805/the-state-of-ai-energy-is-king-and-the-us-is-falling-behind/",
      "description": "Welcome back toÂ The State of AI, a new collaboration between the Financial Times and MIT Technology Review. Every Monday, writers from both publications debate one aspect of the generative AI revolution and how it is reshaping global power. This week, Casey Crownhart, senior reporter for energy at MIT Technology Review and Pilita Clark, FTâ€™s columnist,â€¦",
      "pubDate": "Mon, 10 Nov 2025 16:45:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Why giving up on goals is good for you, and how to know which to ditch",
      "link": "https://www.newscientist.com/article/2501420-why-giving-up-on-goals-is-good-for-you-and-how-to-know-which-to-ditch/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "We admire grit and perseverance, but surprising research suggests that giving up on ambitions in the right way can actually improve our physical and mental health",
      "pubDate": "Mon, 10 Nov 2025 16:00:25 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Ultrasound may boost survival after a stroke by clearing brain debris",
      "link": "https://www.newscientist.com/article/2503750-ultrasound-may-boost-survival-after-a-stroke-by-clearing-brain-debris/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The damage of strokes caused by brain bleeds can be mitigated by removing dead blood cells. Scientists have now found a way of doing this non-invasively, with promising results in mice",
      "pubDate": "Mon, 10 Nov 2025 16:00:16 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "To Have Machines Make Math Proofs, Turn Them Into a Puzzle",
      "link": "https://www.quantamagazine.org/to-have-machines-make-math-proofs-turn-them-into-a-puzzle-20251110/",
      "description": "Marijn Heule turns mathematical statements into something like Sudoku puzzles, then has computers go to work on them. His proofs have been called â€œdisgusting,â€ but they go beyond what any human can do.            \nThe post To Have Machines Make Math Proofs, Turn Them Into a Puzzle first appeared on Quanta Magazine",
      "pubDate": "Mon, 10 Nov 2025 15:27:09 +0000",
      "source": "Quanta Magazine",
      "sourceUrl": "https://www.quantamagazine.org/feed/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Falling asleep isnâ€™t a gradual process â€“ it happens all of a sudden",
      "link": "https://www.newscientist.com/article/2503413-falling-asleep-isnt-a-gradual-process-it-happens-all-of-a-sudden/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Brain activity from more than 1000 people shows a rapid transition from being awake to being asleep, rather than a slow transition between the two states",
      "pubDate": "Mon, 10 Nov 2025 15:00:48 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "AI may blunt our thinking skills â€“ hereâ€™s what you can do about it",
      "link": "https://www.newscientist.com/article/2501634-ai-may-blunt-our-thinking-skills-heres-what-you-can-do-about-it/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "There is growing evidence that our reliance on generative AI tools is reducing our ability to think clearly and critically, but it doesnâ€™t have to be that way",
      "pubDate": "Mon, 10 Nov 2025 14:30:13 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Reimagining cybersecurity in the era of AI and quantum",
      "link": "https://www.technologyreview.com/2025/11/10/1127774/reimagining-cybersecurity-in-the-era-of-ai-and-quantum/",
      "description": "AI and quantum technologies are dramatically reconfiguring how cybersecurity functions, redefining the speed and scale with which digital defenders and their adversaries can operate. The weaponization of AI tools for cyberattacks is already proving a worthy opponent to current defenses. From reconnaissance to ransomware, cybercriminals can automate attacks faster than ever before with AI. Thisâ€¦",
      "pubDate": "Mon, 10 Nov 2025 14:19:28 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "The Download: busting weather myths, and AI heart attack prediction",
      "link": "https://www.technologyreview.com/2025/11/10/1127798/the-download-busting-weather-myths-and-ai-heart-attack-prediction/",
      "description": "This is todayâ€™s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of whatâ€™s going on in the world of technology. Why itâ€™s so hard to bust the weather control conspiracy theory It was October 2024, and Hurricane Helene had just devastated the US Southeast. Representative Marjorie Taylor Greene of Georgia found an abstractâ€¦",
      "pubDate": "Mon, 10 Nov 2025 13:10:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "DARPA and Texas Bet $1.4 Billion on a Unique Foundry",
      "link": "https://spectrum.ieee.org/3d-heterogeneous-integration",
      "description": "A 1980s-era semiconductor fab in Austin, Texas, is getting a makeover. The Texas Institute for Electronics (TIE), as itâ€™s called now, is tooling up to become the only advanced packaging plant in the world that is dedicated to 3D heterogeneous integration (3DHI)â€”the stacking of chips made of multiple materials, both silicon and non-silicon. \nThe fab is the infrastructure behind DARPAâ€™s Next-Generation Microelectronics Manufacturing (NGMM) program. â€œNGMM is focused on a revolution in microelectronics through 3D heterogeneous integration,â€ said Michael Holmes, managing director of the program. \nStacking two or more silicon chips inside the same package makes them act as if they are all one integrated circuit. It already powers some of the most advanced processors in the world. But DARPA predicts silicon-on-silicon stacking will result in no more than a 30-fold boost in performance over whatâ€™s possible with 2D integration. By contrast, doing it with a mix of materialsâ€”gallium nitride, silicon carbide, and other semiconductorsâ€”could deliver a 100-fold boost, Holmes told engineers and other interested parties at the programâ€™s unofficial coming out party, the NGMM Summit, late last month.\nThe new fab will make sure these unusual stacked chips are prototyped and manufactured in the United States. Startups, and there were many at the launch event, are looking for a place to prototype and begin manufacturing ideas that are too weird for anywhere elseâ€”and hopefully bypassing the lab-to-fab valley of death that claims many hardware startups.\nThe state of Texas is contributing $552 million to stand up the fab and its programs, with DARPA contributing the remaining $840 million. After NGMMâ€™s five-year mission is complete, the fab is expected to be a self-sustaining business. â€œWe are, frankly, a startup,â€ said TIE CEO Dwayne LaBrake. â€œWe have more runway than a typical startup, but we have to stand on our own.â€ \nStarting up a 3DHI Fab\nGetting to that point will take a lot of work, but the TIE foundry is off to a quick start. On a tour of the facility, IEEE Spectrum saw multiple chip manufacturing and testing tools in various states of installation and met several engineers and technicians who had started within the past three months. TIE expects all the fabâ€™s tools to be in place in the first quarter of 2026.\nJust as important as the tools themselves is the ability of foundry customers to use them in a predictable manufacturing process. Thatâ€™s something that is particularly difficult to develop, TIE officials explained. At the most basic level, non-silicon wafers are  often not the same size as one another, and they have different mechanical properties, meaning they expand and contract with temperature at different rates. Yet much of the fabâ€™s work will be linking these chips together with micrometer precision.\nThe first phase of getting that done is the development of what are called a process design kit and an assembly design kit. The former provides the rules that constrain semiconductor design at the fab. The latter, the assembly design kit, is the real heart of things, because it gives the rules for the 3D assembly and other advanced packaging.\nNext, TIE will refine those by way of three 3DHI projects, which NGMM is calling exemplars. These are a phased-array radar, an infrared imager called a focal plane array, and a compact power converter. Piloting those through production â€œgives us an initial road mapâ€¦an on-ramp into tremendous innovation across a broader application space,â€ said Holmes.\nThese three very different products are emblematic of how the fab will have to operate once itâ€™s up and running. Executives described it as a â€œhigh-mix, low-volumeâ€ foundry, meaning itâ€™s going to have to be good at doing many different things, but itâ€™s not going to make a lot of any one thing. \nThis is the opposite of most silicon foundries. A high-volume silicon foundry gets to run lots of similar test wafers through its process to work out the bugs. But TIE canâ€™t do that, so instead itâ€™s relying on AIâ€”developed by Austin startup Sandbox Semiconductorâ€”to help predict the outcome of tweaks to its processes.\nAlong the way, NGMM will provide a number of research opportunities. â€œWhat we have with NGMM is a very rare opportunity,â€ said Ted Moise, a professor at UT Dallas and an IEEE Fellow. With NGMM, universities are planning to work on new thermal conductivity films, microfluidic cooling technology, understanding failure mechanisms in complex packages, and more.\nâ€œNGMM is a weird program for DARPA,â€ admitted Whitney Mason, director of the agencyâ€™s Microsystems Technology Office. â€œItâ€™s not our habit to stand up facilities that do manufacturing.â€ \nBut â€œKeep Austin Weirdâ€ is the cityâ€™s unofficial motto, so maybe NGMM and TIE will prove a perfect fit.",
      "pubDate": "Mon, 10 Nov 2025 13:00:03 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Could electric race cars soon be faster than Formula 1?",
      "link": "https://www.newscientist.com/article/2503519-could-electric-race-cars-soon-be-faster-than-formula-1/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The electric cars of the Formula E racing championship can accelerate faster than Formula 1 cars and their top speeds are catching up â€“ but battery capacity would let them down in a head-to-head",
      "pubDate": "Mon, 10 Nov 2025 12:00:07 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "When rift lakes dry up it can cause earthquakes and eruptions",
      "link": "https://www.newscientist.com/article/2503579-when-rift-lakes-dry-up-it-can-cause-earthquakes-and-eruptions/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Lake Turkana in Kenya, known as the cradle of humanity, has shrunk in recent millennia â€“ and the loss of water has led to increased seismic activity, which could have impacted our ancient ancestors",
      "pubDate": "Mon, 10 Nov 2025 10:00:41 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "AI power use forecast finds the industry far off track to net zero",
      "link": "https://www.newscientist.com/article/2503556-ai-power-use-forecast-finds-the-industry-far-off-track-to-net-zero/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Several large tech firms that are active in AI have set goals to hit net zero by 2030, but a new forecast of the energy and water required to run large data centres shows theyâ€™re unlikely to meet those targets",
      "pubDate": "Mon, 10 Nov 2025 10:00:32 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Mysterious holes in Andean mountain may be an Inca spreadsheet",
      "link": "https://www.newscientist.com/article/2503499-mysterious-holes-in-andean-mountain-may-be-an-inca-spreadsheet/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Thousands of holes arranged in a snake-like pattern on Monte Sierpe in Peru could have been a monumental accounting device for trade and tax",
      "pubDate": "Mon, 10 Nov 2025 00:01:52 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Startup Using Nanotips and Naphthalene for New Satellite Thruster",
      "link": "https://spectrum.ieee.org/ion-thruster",
      "description": "It sounds like a NASA pipe dream: a new spacecraft thruster thatâ€™s up to 40 percent more power-efficient than todayâ€™s. Even better, its fuel costs less than a thousandth as much and weighs an eighth of the mass. A startup called Orbital Arc claims it can make such a thruster.\nWith this design, â€œwe can go from a thruster thatâ€™s about a few inches across and several kilograms to a thruster on a chip thatâ€™s about an inch across and has the same thrust output, but weighs about an eighth as much,â€ the companyâ€™s founder, Jonathan Huffman, says.\nAccording to Orbital Arc, the hardware would be small enough to fit on the smallest low Earth orbit satellites but generate enough power for an interplanetary mission. Such inexpensive thrust could bring meaningful savings for satellite operators hoping to dodge debris or mission operators aiming to send probes to distant planets.\nThe key to these innovations is a combination of cheap, readily available fuel, MEMS microfabrication, and a strong love of sci-fi.\nDesigning a Better Thruster \nThrusters generally work by creating and then expelling a plasma, pushing a spacecraft in the opposite direction. Inside ever-popular Hall thrusters, a magnetic field traps electrons in a tight, circular orbit. A noble gasâ€”commonly xenonâ€”drifts into a narrow channel where it collides with the circulating charge knocking off electrons and ionizing it into plasma. A high-voltage electric field then rockets the plasma out the exhaust. \nOrbital Arcâ€™s technology looks a bit different and came about almost coincidentally. Huffman was a biotech consultant and self-described â€œsci-fi nerdâ€ who, in his spare time, had been commissioned to design fictitious technology for a futuristic video game. He had to figure out how spacecraft might maneuver 250 years from now to make the game controls realistic, so he started researching state-of-the-art propulsion systems. \nHe quickly came to understand a limitation of existing ion thrusters he thought could be improved upon within the coming centuries and (spoiler alert) possibly sooner: If a mission requires more thrust, its thruster needs to be heavier. But crucially, â€œthereâ€™s a certain point at which adding more mass to the thruster negates all of the benefits you can get from extra thrust,â€ he says. So, to retain those benefits, thrusters need to be small but mighty. \nHuffmanâ€™s familiarity with biology labs gave him an unexpected edge when it came to propulsion design. Through his job, he learned about nanoscale tips that emit ions used to generate intense electromagnetic fields for biomedical research. Theyâ€™re found in mass spectrometers, instruments that identify unknown chemicals by converting them into ions, accelerating them, and watching how they fly.\nHe suspected that such a system could be miniaturized even more to make the ionization process in a thruster. After a year and a half of developing the concept, Huffman was convinced that his idea for a small thruster had potential beyond a video game. \nAnd he was right. Each Orbital Arc thruster has a chip at its heart with millions of micrometer-scale, positively charged tips embedded in it and channels to direct gas flowâ€”naphthalene flows in, and ions flow out. \nAs naphthalene molecules pass the charged tips, the molecules become polarizedâ€”here, that means a moleculeâ€™s electrons bunch up on one of its sides. Because of the uneven field created by the charge, the molecules get dragged toward a tip and are then trapped there, unable to escape until they release electrons. \nOnce they release electrons, â€œyou have an ion thatâ€™s at the point of a really sharp positively charged object, and it itself is now positively charged. So it accelerates,â€ Huffman explains. The repelled ions fly by and spray out into space, propelling the spacecraft forward.\nAn advantage of this design is the power savings that come from avoiding the internal plasma generation that other thrusters rely on, Huffman says. â€œPlasmas have losses because everythingâ€™s in a big soup mixed together,â€ Huffman explains. Free electrons in a plasma can recombine with ions to produce neutral atoms â€œand now Iâ€™ve lost the energy that I put in to make that charged particle. Itâ€™s a waste of power.â€ Recent calculations show the naphthalene nanotip thruster providing a 30 to 40 percent improvement in power efficiency, he claims.\nA recent demonstration showed that the Orbital Arc design is not only able to capitalize on the power savings of avoiding plasmas all together, but also outperforms other designs using similar technology. In a recent test, just six of Orbital Arcâ€™s tips were able to generate about three times more ion current than an array of 320,000 tips from a group from MIT, Huffman says.\nTwo and a half years after his â€œahaâ€ moment (and after â€œbuilding the whole darn thing in Excelâ€), Huffman is the CEO of Orbital Arc, a startup testing four working prototypes of its tiny tips-on-chips. \nThe thruster is not only innovative for its size, but also for its fuel. Naphthaleneâ€”the main ingredient in mothballsâ€”is a readily available byproduct of oil refineries. The compound may smell bad, but itâ€™s safe to handle and extremely cheap, Huffman says, costing around US $1.50 per kilogram compared to some $3,000 per kilogram for xenon.\nOrbital Arcâ€™s use of naphthalene aids in their shrinking of product costs, which the company claims is at 25 to 33 percent of traditional Hall thrusters. â€œI think thatâ€™s believable,â€ says Jonathan MacArthur, a postdoctoral researcher at Princeton Universityâ€™s Electric Propulsion and Plasma Dynamics Laboratory. â€œWhat remains to be seen is, okay, itâ€™s cheap, but if I put diesel in my gas car because itâ€™s on sale, that doesnâ€™t necessarily bode well for the engine in my car.â€ He wishes the startup would release data to back up their cost claimsâ€”and while theyâ€™re at it, data to back up performance claims, as well.\nFrom Prototype to Flight\nFor now, in the prototype stage, each chip contains only six tips, fabricated using MEMS manufacturing processes in a cleanroom at Oak Ridge National Laboratory. But the next step is to manufacture a full-scale version of the chip in a university lab, Huffman says.\nThen, the company will need to build the thruster that goes around the chip. â€œThatâ€™s a relatively simple device. Itâ€™s a valve, itâ€™s a few wires, itâ€™s a few structural components. Very, very straightforward,â€ Huffman claims. He says heâ€™ll need to integrate all of those parts before running through vibration testing, radiation testing, thermal cycling, and other steps on the way to achieve flight qualification. â€œTwo years from now, I can have a product that is sellable, probably.â€\nHuffman thinks Orbital Arcâ€™s initial customers would be small teams, like startups or research groups. Heâ€™s confident that theyâ€™ll be willing to try the new thrusters, despite the risks inherent to new technologies, because of the expected performance at low cost. â€œSo some folks just wonâ€™t have any choice but to buy it, even if it hasnâ€™t flown before. If they want to do the mission, theyâ€™re going to take the risk,â€ he says.\nPrincetonâ€™s MacArthur is skeptical of that claim. â€œWhen youâ€™re choosing a propulsion system, generally data and heritage is everything.â€ Heâ€™s not so sure that customers will be willing to take on the risk of a new thruster without a history of flight. \nStill, some CubeSat-scale missions may agree to use new thrusters at a discount, suggests Oliver Jia-Richards, who studies in-space propulsion at the University of Michigan. Customers may also be willing to take a chance on Orbital Arc because other startups, like Enpulsion, have been recently successful with their new electric propulsion technology, he says. But â€œwith this kind of thing, thereâ€™s always risks.â€\nAfter targeting small missions, Huffman wants to â€œbuild something where we show off a bit.â€ He notes that, as of yet, no satellite has completed a round trip to the moon after a year in Earthâ€™s orbit without refueling. Itâ€™s funding dependent and there may be more attractive opportunities that come up, â€œso weâ€™ll see,â€ he says.\nAnd heâ€™s not stopping there. â€œWe are tapping into a mathematical reality,â€ Huffman says. â€œIf you cut dry mass off of spacecraft, you gain exponential benefits in its performance because of the way the rocket equation works. You get exponentially penalized for extra dry mass.â€ \nBy integrating Orbital Arcâ€™s thrusters, he says, a mission could cut solar panel and power supply mass because its drive is more power efficient, cut tank mass because naphthalene doesnâ€™t require a pressure vessel unlike xenon, and cut thruster mass itself. With these savings, â€œyou go from flying one-way science missions to Mars to flying two-way human-rated missions to Jupiter without refueling,â€ Huffman claims.\nSo while the thruster is Orbital Arcâ€™s first step, Huffman envisions an ultralight spacecraft bus nextâ€”arriving long before the far-future era of the video game that inspired it.\nThis post was corrected on 11 November 2025 to indicate the proper cost savings of the new technology.",
      "pubDate": "Sun, 09 Nov 2025 14:00:02 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "James Watson, co-discoverer of DNAâ€™s double helix, has died aged 97",
      "link": "https://www.newscientist.com/article/2503570-james-watson-co-discoverer-of-dnas-double-helix-has-died-aged-97/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "As one of the most influential scientists of the 20th century, James Watson pioneered the field of genetics and left behind a complicated legacy",
      "pubDate": "Fri, 07 Nov 2025 21:13:45 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "IEEE WIE Podcast Focuses on Workplace Issues for Women in Tech",
      "link": "https://spectrum.ieee.org/ieee-wie-podcast-women-in-tech",
      "description": "For anyone working in todayâ€™s rapidly evolving science, technology, engineering, and mathematics fields, visibility, authenticity, and connection are no longer optional; they are essential. But there is a lack of resources for STEM professionals, especially women, looking to express themselves fully, build meaningful networks, and lead with confidence.\nTo help, IEEE Women in Engineering (WIE) recently launched a podcast series in which experts from around the world inspire and inform to ignite change.\nThe series aims to amplify the diverse experiences of women from STEM fields. Through candid conversations and expert insights, the podcast goes beyond technical talks to explore the human side of innovation, navigating burnout, balancing career ambition with well-being, and building successful, sustainable careers.\nThe series is a volunteer and staff-run initiative.\nâ€œIn the early days of planning, our vision was just a spark shared among passionate volunteers eager to shape each episode and guest experience,â€ says Geetika Tandon, cochair of the IEEE WIE podcast subcommittee. â€œSeeing our podcast grow from those first conversations into a vibrant reality has been truly rewarding. We canâ€™t wait for it to expand further.â€\nâ€œIâ€™m excited that weâ€™ve brought the drawings on our whiteboard and day planners to life,â€ says Kelly Onu, who is also cochair.\nNew episodes are released on the third Wednesday of each month.\nNavigating dual-career dynamics\nThe podcastâ€™s premier episode, â€œMoms Who Innovate,â€ which debuted in May, features candid conversations with two executive coaches, authors, and TEDx speakers. Adaeze Iloeje-Udeogalanya, is the founder of African Women in STEM, which provides education, mentoring, and networking opportunities. Cassie Leonard is a seasoned aerospace professional who founded ELMM Coaching. Leonard offers one-on-one advice for professionals looking to grow their career and achieve a better work-life balance. She authored STEM Moms: Design, Build, and Test to Create the Work-Life of Your Dreams, a book that guides women by drawing from her experiences as a working mother.\nOnu, who moderated the episode, spoke with Iloeje-Udeogalanya and Leonard about the ebb and flow of being a mother while building a career. Both guests described how their background as engineers shaped the way they approach motherhood and community. They emphasized the importance of creating a support system that makes the busier times of life more manageable.\nLeonard said she â€œengineered her neighborhoodâ€ and shares the responsibilities of dropping off children at school, babysitting after school, and other day-to-day tasks.\nâ€œAs the podcast series grows, our mission is to shine a spotlight on the real-life adventures (and occasional misadventures) of women in STEM. We want to share late-night brainstorms, coffee-fueled breakthroughs, and the moment when someone finally figures out how to unmute themselves on virtual meeting platforms.â€ â€”Geetika Tandon\nInnovation for moms isnâ€™t only about professional success, the duo said, but also about designing the kind of community that helps them thrive.\nThe June episode, â€œGlobal Perspectives on Women in STEM,â€ led by Tandon, offered practical strategies for navigating work-life-balance challenges. Together with guest Sanyogita Shamsunder, CTO of telecommunications company GeoLinks in San Francisco, Tandon explored different perspectives of women around the world.\nRawan Alghamdi, a wireless communication researcher at the King Abdullah University of Science and Technology, in Saudi Arabia, and an IEEE graduate student member hosted Augustâ€™s episode, â€œPIE Framework: Presence, Image, and Exposure for Professionals in STEM.â€ Alghamdi spoke with Jahnavi Brenner, an executive coach and former engineer, who explained the PIE model, which challenges the long-held belief that technical skills alone are enough to advance oneâ€™s career.\nBrenner said professionals must strategically build an authentic personal brand to dictate how they are perceived by colleagues and how visible they are within their networks and industry. She said it is especially vital for women and underrepresented groups, who often face systemic barriers to recognition and promotion.\nOctoberâ€™s episode, â€œBalancing Work and Life in STEM Careers,â€ tackled struggles parents face raising a family while working full time. It was moderated by Abinaya Inbamani, a mentor who has contributed to the successful deployment of IoT systems used for smart health care, renewable energy, and cybersecurity.\nShe covered the intense logistics and emotional toll of balancing a demanding career with the responsibilities of parenthood.\nListeners also learned time-management strategies and boundary-setting techniques, such as reframing guilt as a reminder of care and responsibility rather than failure; accepting that itâ€™s all right to procrastinate occasionally rather than push through unhealthy stress; and organizing the day with clear boundaries between work and home.\nâ€œWe donâ€™t have to do it all,â€ Inbamani said. â€œSometimes balance is simply choosing what matters most in that moment.â€ \nWhatâ€™s next for the podcast\nUpcoming episodes will focus on being present parents, setting boundaries in high-pressure environments, and redefining success on oneâ€™s own terms, Tandon and Onu say.\nIn the works is an episode spotlighting tech trailblazer Nimisha Morkonda Gnanasekaran, who was recognized by the IEEE Computer Society as one of its Top 30 Early Career Professionals this year. She is the director of data science and advanced analytics at Western Digital, based in San Jose, Calif.\nAnother episode, Tandon and Onu say, will feature a conversation with Cynthia Kane, author of The Pause Principle: How to Keep Your Cool in Tough Situations, on navigating difficult workplace conversations without shutting down or losing oneâ€™s temper. The episode will tackle critical issues and career struggles women face, Tandon and Onu say. A study that found as many as 50 percent of women leave their STEM career within five years.\nGlobal reach and impact of the podcast\nIEEE WIE is seeing the impact the podcast is having on listeners. Several say they tune in not just for advice but also to connect with others. Others say the podcast makes them feel they are not alone in their challenges or career aspirations.\nThe majority of listeners are in Canada, India, Japan, Saudi Arabia, TÃ¼rkiye, and the United States. Onu says she hopes the audience expands to include more countries.\nâ€œI hope this podcast hops across continents, sneaks into earbuds everywhere, and becomes a trusty sidekick in womenâ€™s STEM journeysâ€”cheering them on as they conquer equations, break barriers, and maybe even invent a robot that makes perfect coffee,â€ Tandon says. â€œAs the podcast series grows, our mission is to shine a spotlight on the real-life adventures (and occasional misadventures) of women in STEM. We want to share late-night brainstorms, coffee-fueled breakthroughs, and the moment when someone finally figures out how to unmute themselves on virtual meeting platforms.â€\nThrough personal tales, inspiring journeys, and a parade of trailblazing leaders who have tackled obstacles, IEEE WIE is celebrating the grit, wit, and brilliance of women in STEM.\nWhether youâ€™re a student just beginning your STEM journey, a mid-career professional seeking clarity, or a leader looking to give back to your profession, the podcast offers a space to learn, reflect, and rise together.",
      "pubDate": "Fri, 07 Nov 2025 20:00:03 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Enceladusâ€™s ocean may be even better for life than we realised",
      "link": "https://www.newscientist.com/article/2503397-enceladuss-ocean-may-be-even-better-for-life-than-we-realised/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The buried ocean on Saturnâ€™s moon Enceladus seems to be stable across extremely long periods of time, making it an even more promising place to hunt for life",
      "pubDate": "Fri, 07 Nov 2025 19:00:48 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Having children plays a complicated role in the rate we age",
      "link": "https://www.newscientist.com/article/2503299-having-children-plays-a-complicated-role-in-the-rate-we-age/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The effort of reproducing may divert energy away from repairing DNA or fighting illness, which could drive ageing, but a new study suggests that is only the case when environmental conditions are tough",
      "pubDate": "Fri, 07 Nov 2025 19:00:24 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Video Friday: This Drone Drives and Fliesâ€”Seamlessly",
      "link": "https://spectrum.ieee.org/video-friday-multimode-drone",
      "description": "Video Friday is your weekly selection of awesome robotics videos, collected by your friends at IEEE Spectrum robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please send us your events for inclusion.\nICRA 2026: 1â€“5 June 2026, VIENNA\nEnjoy todayâ€™s videos!\n\n \nUnlike existing hybrid designs, Duawlfin eliminates the need for additional actuators or propeller-driven ground propulsion by leveraging only its standard quadrotor motors and introducing a differential drivetrain with one-way bearings. The seamless transitions between aerial and ground modes further underscore the practicality and effectiveness of our approach for applications like urban logistics and indoor navigation.\n\n[ HiPeR Lab ]\n\nI appreciate the softness of NEOâ€™s design, but those fingers look awfully fragile.\n\n[ 1X ]\n\nImagine reaching into your backpack to find your keys. Your eyes guide your hand to the opening, but once inside, you rely almost entirely on touch to distinguish your keys from your wallet, phone, and other items. This seamless transition between sensory modalities (knowing when to rely on vision versus touch) is something humans do effortlessly but robots struggle with. The challenge isnâ€™t just about having multiple sensors. Modern robots are equipped with cameras, tactile sensors, depth sensors, and more. The real problem is **how to integrate these different sensory streams**, especially when some sensors provide sparse but critical information at key moments. Our solution comes from rethinking how we combine modalities. Instead of forcing all sensors through a single network, we train separate expert policies for each modality and learn how to combine their action predictions at the policy level.\n\nMulti-university Collaboration presented via [ GitHub ]\nThanks, Haonan!\n\nHappy (somewhat late) Halloween from Pollen Robotics!\n\n[ Pollen Robotics ]\n\nIn collaboration with our colleagues from Iowa State and University of Georgia, we have put our pipe-crawling worm robot to test in the field. See it crawls through corrugated drainage pipes in a stream, and a smooth section of a subsurface drainage system.\n\n[ Paper ] from [ Smart Microsystems Laboratory, Michigan State University ]\n\nHeterogeneous robot teams operating in realistic settings often must accomplish complex missions requiring collaboration and adaptation to information acquired online. Because robot teams frequently operate in unstructured environments â€” uncertain, open-world settings without prior maps â€” subtasks must be grounded in robot capabilities and the physical world. We present SPINE-HT, a framework that addresses these limitations by grounding the reasoning abilities of LLMs in the context of a heterogeneous robot team through a three-stage process. In real-world experiments with a Clearpath Jackal, a Clearpath Husky, a Boston Dynamics Spot, and a high-altitude UAV, our method achieves an 87% success rate in missions requiring reasoning about robot capabilities and refining subtasks with online feedback.\n\n[ SPINE-HT ] from [ GRASP Lab, University of Pennsylvania ]\n\nAstribot keeping itself busy at IROS 2025.\n\n[ Astribot ]\n\nIn two papers published in Matter and Advanced Science, a team of scientists from the Physical Intelligence Department at the Max Planck Institute for Intelligent Systems in Stuttgart, Germany, developed control strategies for influencing the motion of self-propelling oil droplets. These oil droplets mimic single-celled microorganisms and can autonomously solve a complex maze by following chemical gradients. However, it is very challenging to integrate external perturbation and use these droplets in robotics. To address these challenges, the team developed magnetic droplets that still possess life-like properties and can be controlled by external magnetic fields. In their work, the researchers showed that they are able to guide the dropletâ€™s motion and use them in microrobotic applications such as cargo transportation.\n\n[ Max Planck Institute ]\n\nEveryone has fantasized about having an embodied avatar! Full-body teleoperation and full-body data acquisition platform is waiting for you to try it out!\n\n[ Unitree ]\n\nItâ€™s not a humanoid, but it right now safely does useful things and probably doesnâ€™t cost all that much to buy or run.\n\n[ Naver Labs ]\n\nThis paper presents a curriculum-based reinforcement learning framework for training precise and high-performance jumping policies for the robot `Olympusâ€™. Separate policies are developed for vertical and horizontal jumps, leveraging a simple yet effective strategy. Experimental validation demonstrates horizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to 1.0 m. Additionally, we show that with only minor modifications, the proposed method can be used to learn omnidirectional jumping.\n\n[ Paper ] from [ Autonomous Robots Lab, Norwegian University of Science and Technology ]\n\nHeavy payloads are no problem for it: The new KR TITAN ultra moves payloads of up to 1500 kg, making the heavy lifting extreme in the KUKA portfolio.\n\n[ Kuka ]\n\nGood luck getting all of the sand out of that robot. Perhaps a nice oil bath is in order?\n\n[ DEEP Robotics ]\n\nThis CMU RI Seminar is from Yuke Zhu at University of Texas at Austin, on â€œToward Generalist Humanoid Robots: Recent Advances, Opportunities, and Challenges.â€\n\nIn an era of rapid AI progress, leveraging accelerated computing and big data has unlocked new possibilities to develop generalist AI models. As AI systems like ChatGPT showcase remarkable performance in the digital realm, we are compelled to ask: Can we achieve similar breakthroughs in the physical world â€” to create generalist humanoid robots capable of performing everyday tasks? In this talk, I will outline our data-centric research principles and approaches for building general-purpose robot autonomy in the open world. I will present our recent work leveraging real-world, synthetic, and web data to train foundation models for humanoid robots. Furthermore, I will discuss the opportunities and challenges of building the next generation of intelligent robots.\n[ Carnegie Mellon University Robotics Institute ]",
      "pubDate": "Fri, 07 Nov 2025 18:30:03 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "A distant galaxy is being strangled by the cosmic web",
      "link": "https://www.newscientist.com/article/2503265-a-distant-galaxy-is-being-strangled-by-the-cosmic-web/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "A dwarf galaxy 100 million light years away is being stripped of its crucial star-forming gas, and it seems that the cosmic web is siphoning off this gas as the galaxy passes through",
      "pubDate": "Fri, 07 Nov 2025 16:00:45 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Physicists Take the Imaginary Numbers Out of Quantum Mechanics",
      "link": "https://www.quantamagazine.org/physicists-take-the-imaginary-numbers-out-of-quantum-mechanics-20251107/",
      "description": "Quantum mechanics has at last been formulated exclusively with real numbers, bringing a mathematical puzzle at the heart of the theory into a new era of inquiry.             \nThe post Physicists Take the Imaginary Numbers Out of Quantum Mechanics first appeared on Quanta Magazine",
      "pubDate": "Fri, 07 Nov 2025 15:13:54 +0000",
      "source": "Quanta Magazine",
      "sourceUrl": "https://www.quantamagazine.org/feed/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "We may never figure out where interstellar comet 3I/ATLAS came from",
      "link": "https://www.newscientist.com/article/2503047-we-may-never-figure-out-where-interstellar-comet-3i-atlas-came-from/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The surface of comet 3I/ATLAS may have been so radically altered by cosmic rays that deducing its home star system would be impossible",
      "pubDate": "Fri, 07 Nov 2025 15:00:27 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "The Download: a new home under the sea, and cloning pets",
      "link": "https://www.technologyreview.com/2025/11/07/1127765/the-download-a-new-home-under-the-sea-and-cloning-pets/",
      "description": "This is todayâ€™s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of whatâ€™s going on in the world of technology. The first new subsea habitat in 40 years is about to launch Vanguard feels and smells like a new RV. It has long, gray banquettes that convert into bunks, a microwave cleverly hiddenâ€¦",
      "pubDate": "Fri, 07 Nov 2025 13:10:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "The first new subsea habitat in 40 years is about to launch",
      "link": "https://www.technologyreview.com/2025/11/07/1127682/vanguard-deep-subsea-habitat-launch/",
      "description": "Vanguard feels and smells like a new RV. It has long, gray banquettes that convert into bunks, a microwave cleverly hidden under a counter, a functional steel sink with a French press and crockery above. A weird little toilet hides behind a curtain. But some clues hint that you canâ€™t just fire up Vanguardâ€™s engineâ€¦",
      "pubDate": "Fri, 07 Nov 2025 10:00:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Cloning isnâ€™t just for celebrity pets like Tom Bradyâ€™s dog",
      "link": "https://www.technologyreview.com/2025/11/07/1127692/cloning-celebrity-pets-tom-brady-dog-conservation/",
      "description": "This week, we heard that Tom Brady had his dog cloned. The former quarterback revealed that his Junie is actually a clone of Lua, a pit bull mix that died in 2023. Bradyâ€™s announcement follows those of celebrities like Paris Hilton and Barbra Streisand, who also famously cloned their pet dogs. But some believe thereâ€¦",
      "pubDate": "Fri, 07 Nov 2025 10:00:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Co-Captain Allows Ships to Share Important Navigational Data",
      "link": "https://spectrum.ieee.org/ship-navigation-orca-ai",
      "description": "A new onboard system allows ocean-going vessels to share real-time sea condition data, giving crews early warnings and helping them navigate more safely. The system will analyze data related to navigation, vessel behavior, and the environment to give ship crews guidance at sea.\nWhile casualties from ship collisions and groundings have declined, the overall number of maritime incidents are on the rise, up 22 percent in recent years, driven by aging vessels and equipment failures.\nOrca AI, a London-based autonomous maritime navigation company, has introduced a software feature called Co-Captain, aiming to reduce those incidents. Co-Captain is an addition to the companyâ€™s existing SeaPod real-time decision support system, which bridge officers can use while at sea to navigate better.\n  Co-Captain provides information about severe weather, including recommendations to specific ships based on their size and shape.Orca AI\nâ€œCo-Captain is a network of vessels using Orca to capture events worldwide and share insights. Think of it like the navigation app you use in your car: it tells you about traffic or roadblocks in advance so you can adjust your route,â€ says Yarden Gross, the CEO and co-founder of Orca AI.\nGross says that Co-Captain frequently collects data from sensors on board vessels and sends it to the cloud to improve ship performance and safety for vessels globally.\nOrca AIâ€™s Maritime Solutions\nOrcaAI, founded in 2018 by Gross and Dor Raviv, the CTO, began with SeaPod and Fleet View. While SeaPod collects and analyzes data on individual ships, Fleet View gathers that data in the cloud to give fleet managers on shore better visibility into larger operations.\nCo-Captain integrates with the existing system to provide proactive insights to improve fleet performance and safety. Today, ship officers rely on tools like radar, the automatic identification system (AIS), and the Electronic Chart Display and Information System (ECDIS) monitor the positions of other vessels and avoid collisions, but much of the work remains manual.\n  Co-Captain identifies various navigational hazards to a shipâ€™s crew. The crew can also manually tag obstacles or other concerns.Orca AI\nGross described Co-Captain as the next generation of AIS, the network that transmits basic information like a shipâ€™s position, name, and heading over very high frequency (VHF) signals ranging from 30 to 300 megahertz. Unlike AIS, which tracks only a shipâ€™s position, Co-Captain also monitors onboard conditions. For example, if a ship reports a pitch of 3 degrees and a roll of 5 degrees in rough seas, Co-Captain uses that data to anticipate how current conditions will impact nearby ships, adjusted for their size and design. Co-Captain then sends tailored recommendations to those vesselsâ€™ crews.\nâ€œEvery ship acts as a node in a larger network, and each nodeâ€”the vessel itselfâ€”has an onboard AI platform. This platform collects data from multiple sensors in real time,â€ Gross says. Using cameras and computer vision, the AI model can detect bad weather, low visibility, tall waves, or strong winds, then the platform analyzes the data to provide tailored guidance.\nAll data is anonymized. Gross says that a shipâ€™s movements, timing, or route can reveal valuable information. â€œBy anonymizing the data, Co-Captain can share critical safety alerts such as GPS interference, severe weather, or high traffic without ever exposing which vessel reported it or where it came from.â€\nGross says that Orca AI is working on integrating Co-Captain with more bridge systems, such as Navigational Telex (NAVTEX) and ECDIS, so that relevant alerts and updates are centralized.\nThe companyâ€™s long-term goal is to provide real-time notifications focused on the most important events along a shipâ€™s route, giving captains information they can act on quickly to support safer and more efficient operations. The platform is already in use on over 1,200 vessels.",
      "pubDate": "Thu, 06 Nov 2025 23:19:54 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Menifeeâ€™s EV-Powered Homes: A New Era in Energy Independence",
      "link": "https://spectrum.ieee.org/evs-keep-homes-lit",
      "description": "In Menifee, Calif., six newly built homes are testing a first for North America: electric vehicles that can power houses through the Combined Charging System (CCS) high-power DC charging standard. Each home uses a host Kia EV9 electric vehicle connected to a Wallbox Quasar 2 bidirectional charger, allowing the carâ€™s 100-kilowatt-hour (kWh) battery to run essential circuits during blackouts or periods when electricity prices are high. The setup is the first residential vehicle-to-home (V2H) system in the United States that uses the Combined Charging System (CCS) standard. The CCS is the charging system commonly used in European and North American residential and public charging facilities.\nSince July, the homesâ€™ smart electrical panels have automatically managed two-way power flowâ€”charging vehicles from the grid or rooftop solar, then reversing the flow of energy when needed. The system isolates each home from the grid during an outage, preventing any current from flowing into external power lines and endangering utility crews and nearby equipment.\nâ€œThis project is demonstrating that bidirectional charging with CCS can work in occupied homes,â€ says Scott Samuelsen, founding director of the Advanced Power and Energy Program (APEP) at the University of California, Irvine, which is monitoring the two-year trial. â€œItâ€™s a step toward vehicles that not only move people but also strengthen the energy system.â€\nMenifee means a lot\nFor more than a decade, two-way charging has been availableâ€”but mostly restricted to Japan. Back in 2012 the Nissanâ€™s LEAF-to-Home program proved the idea viable after the TÅhoku earthquake and tsunami, but that Nissan system relied on the CHAdeMO standard, little used outside of Japan. Most North American and European manufacturers chose CCS insteadâ€”a standard that, until recently, supported only one-way fast DC charging.\nThat distinction makes Menifeeâ€™s V2H-enabled neighborhood notable: itâ€™s the first CCS-based V2H deployment in occupied homes, giving researchers real-world field data on a technology thatâ€™s been long trapped in pilot programs. The pairing of the Kia EV9 SUV with Wallboxâ€™s commercially available Quasar 2 can deliver up to 12 kilowatts of power from the vehicle to the home.\nItâ€™s a step toward vehicles that not only move people, but also strengthen the energy system.â€\n â€“Scott Samuelsen, UC Irvine\n\nElsewhere, momentum towards commercial V2H has slowed. Fordâ€™s F-150 Lightning supports home backup through Sunrun, but Sunrun equipment is not CCS-compatible. Whatâ€™s more, Ford has announced a production pause for the pickup truck, which has delayed expansion. GMâ€™s Ultium Homeâ€”a  V2H system that works with the automakerâ€™s Cadillac Lyriq, Cadillac Escalade IQ, Chevrolet Blazer, Chevrolet Equinox, Chevrolet Silverado, and GMC Sierra EVsâ€” faces similar setbacks. Teslaâ€™s PowerShare V2H feature is still stuck in a limited, early commercial rollout, with bidirectional compatibility restricted to the companyâ€™s Cybertruck. Menifee, by contrast, is producing operational data in real households.\nWhy CCS Matters\nWhen electric vehicles first hit the market, CCS was designed for one job: move power quickly from the grid to the car. The main goal was reliable, standardized, fast charging. That fact helps explain the difference between CCS public chargers, (many of which are rated for 350-kilowatts or more) and their CHAdeMO-based counterparts, which typically max out at 100 kW (but are capable of providing home backup or grid services).\nBidirectional operation wasnâ€™t included in the original CCS standard for several reasons. Early automakers and utilities worried about safety risks, grid interference, and added hardware cost. So CCSâ€™s original communication protocol linking EVs and charging stationsâ€”ISO 15118â€”didnâ€™t even include an electronic handshake for power export. The 2022 update, ISO 15118-20, added secure two-way communication, enabling CCS vehicles to supply energy to buildings and the grid.\nWallboxâ€™s Quasar 2 residential charger implements the update through an active-bridge converter circuit built with silicon-carbide transistors, achieving efficient bidirectional flow. Its 12-kW power rating can support typical critical loads in a house, such as heating and cooling, refrigeration, and networking, says Aleix MaixÃ© Sas, a system electronics architect at Wallbox.\n  As the companyâ€™s name humbly suggests, Wallboxâ€™s chargers look like plain old boxesâ€”although they contain high-tech components.Wallbox\nThe Menifee blueprint\nEach of the Menifee homes outfitted with a V2H system combines a rooftop solar array with a 13-kWh SunVault stationary battery from SunPower. During normal operation, solar energy powers daily household loads and charges the stationary battery. On abundantly sunny days, the solar panels can also top up the Kia EV9â€™s battery. When the grid failsâ€”or when energy prices spikeâ€”the home isolates itself: Solar power and energy stored in the SunVault keep essential systems and appliances going, while the EV battery extends power if the outage persists.\nThis past summer, the UC Irvine researchers tracked how solar output, stationary storage, and vehicle power interacted under summer demand and wildfire-related grid stress. They found that â€œthe vehicle adds a major resilience feature,â€ according to Samuelsen, who is the Menifee project manager. â€œIt can relieve grid strain, increase renewable utilization, and lower costs by supplying power during peak-rate hours.â€\nEngineering the Two-Way Home\nHome builders and the makers of electric vehicle service equipment such as Wallbox are not the only entities reconsidering how to meet the engineering demands V2H introduces. Utilities, too, must make changes to accommodate bidirectional power flow. Interconnection procedures and energy pricing structures are among the factors that must be redesigned or reconsidered.\nA Glimpse of the Energy Future\nAnalysts expect double-digit annual growth in bidirectional-charging system sales through the late 2020s as costs fall and standards mature. In regions facing wildfire- or storm-related outages and steep time-of-use pricing curves, projects like Menifeeâ€™s are showing a clear path towards the use of cars as huge and flexible energy reserves.\nWhen EV batteries can supply energy for homes as easily as they do for propulsion, the boundary between transportation and energy will begin to disappearâ€”and with it, old concepts regarding whoâ€™s an energy supplier and whoâ€™s a customer.",
      "pubDate": "Thu, 06 Nov 2025 21:00:03 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "A three-legged lion has learned to hunt in a completely unexpected way",
      "link": "https://www.newscientist.com/article/2503282-a-three-legged-lion-has-learned-to-hunt-in-a-completely-unexpected-way/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Jacob, an 11-year-old lion, has defied expectations by surviving for years after losing a leg â€“ now we know his success is down to an innovative hunting strategy",
      "pubDate": "Thu, 06 Nov 2025 18:00:15 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "How Starting a Side Project Can Help Cool Off Burnout",
      "link": "https://spectrum.ieee.org/starting-a-side-project",
      "description": "This article is crossposted from IEEE Spectrumâ€™s careers newsletter. Sign up now to get insider tips, expert advice, and practical strategies, written in partnership with tech career development company Taro and delivered to your inbox for free!\nAt its core, engineering is an act of creation. This is why many of us chose to become engineers: We love to build things.\nBut especially if you have a private sector job, itâ€™s easy to forget that passion to build as you climb up the corporate ladder. Somewhere between quarterly planning meetings and incident retrospectives, we often lose the joy of creation in our corporate jobs. Large companies require a level of bureaucracy and specialization that is often at odds with building something new.\nThatâ€™s why I frequently recommend burned-out engineers to do something very simple: Start a side project. During 15 years working across various tech stacks and companies, this has been the most straightforward, underrated, and powerful way to regain my excitement at work.\nBeyond rekindling a passion for creation, side projects have many other benefits. Side projects let us explore new technologies or problem spaces. We can leverage newer ideas that our companies may be hesitant to adopt. And you donâ€™t need to get buy-in from a manager or explain the business justification. Start using a technology simply because you want to learn about it. \nWhen you build something through a side project, your depth of understanding is far greater than just following a tutorial or reading about it. I can attribute many of my career opportunities to the projects Iâ€™ve built and published outside of my day job. Some of these projects, like my career growth platform Taro, even turn into companies!\nWeâ€™ve entered the golden age for side projects because theyâ€™re so much more accessible. Compared to a decade ago, itâ€™s significantly easier to research, build, and deploy your creation. Even compared to two years ago, youâ€™re much less likely now to waste hours wrestling with some configuration rabbit hole. Just ask ChatGPT or Gemini for help!\nThe benefits of a personal project are real: passion, learning, career growth, and fun. And theyâ€™re easier than ever to create. Nowâ€™s the time to create your side project portfolio.\nâ€”Rahul\nHow to Land a Job in Quantum Computing\nThe quantum computing industry is growing, opening up new opportunities for engineersâ€”and you donâ€™t necessarily need a background in quantum physics to take these positions. So what skills do you need? See five key tips for breaking into the field from recruiters and researchers now working in quantum computing jobs. \nRead more here.\nEmpowering Women in the Power Industry\nMini Thomas has built a highly successful career as an expert in power systems and smart gridsâ€”thanks in part, she says, to support from her family. Now a professor of electrical engineering in New Delhi, Thomas mentors women in the power industry, helping to expand the female leadership pipeline in India. \nRead more here.\nAre Kids Still Looking for Careers in Tech?\nThe growth of AI and changes in funding for scientific research have spurred uncertainty for young people considering careers in STEM. To get a sense of how these changes are affecting the next generationâ€™s aspirations, Wired spoke to five high school seniors across the United States about their futures.Read more here.",
      "pubDate": "Thu, 06 Nov 2025 17:56:49 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Digital map lets you explore the Roman Empire's vast road network",
      "link": "https://www.newscientist.com/article/2503325-digital-map-lets-you-explore-the-roman-empires-vast-road-network/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Archaeologists have compiled the most detailed map yet of roads throughout the Roman Empire in AD 150, totalling almost 300,000 kilometres in length",
      "pubDate": "Thu, 06 Nov 2025 16:00:09 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "The Download: how doctors fight conspiracy theories, and your AI footprint",
      "link": "https://www.technologyreview.com/2025/11/06/1127666/the-download-how-doctors-fight-conspiracy-theories-and-your-ai-footprint/",
      "description": "This is todayâ€™s edition ofÂ The Download,Â our weekday newsletter that provides a daily dose of whatâ€™s going on in the world of technology. How conspiracy theories infiltrated the doctorâ€™s office As anyone who has googled their symptoms and convinced themselves that theyâ€™ve got a brain tumor will attest, the internet makes it very easy to self-(mis)diagnoseâ€¦",
      "pubDate": "Thu, 06 Nov 2025 13:10:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Stop worrying about your AI footprint. Look at the big picture instead.",
      "link": "https://www.technologyreview.com/2025/11/06/1127579/ai-footprint/",
      "description": "Picture it: Iâ€™m minding my business at a party, parked by the snack table (of course). A friend of a friend wanders up, and we strike up a conversation. It quickly turns to work, and upon learning that Iâ€™m a climate technology reporter, my new acquaintance says something like: â€œShould I be using AI? Iâ€™veâ€¦",
      "pubDate": "Thu, 06 Nov 2025 11:00:00 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Grafting trick could let us gene-edit a huge variety of plants",
      "link": "https://www.newscientist.com/article/2502509-grafting-trick-could-let-us-gene-edit-a-huge-variety-of-plants/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Many plants including cocoa, coffee and avocado cannot be gene-edited but a technique involving grafting could change that, opening the door to more productive and nutritious varieties",
      "pubDate": "Thu, 06 Nov 2025 09:00:22 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Skeleton with brutal injuries identified as duke assassinated in 1272",
      "link": "https://www.newscientist.com/article/2503197-skeleton-with-brutal-injuries-identified-as-duke-assassinated-in-1272/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The identity of a skeleton buried under a Budapest convent has been confirmed as BÃ©la of MacsÃ³, a Hungarian royal murdered in a 13th-century power struggle, and archaeologists have pieced together how the attack unfolded",
      "pubDate": "Thu, 06 Nov 2025 08:00:36 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Is the expansion of the universe slowing down?",
      "link": "https://www.newscientist.com/article/2503263-is-the-expansion-of-the-universe-slowing-down/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "It is widely accepted that the universe is expanding at an accelerating rate, but now researchers say our measurements of the mysterious force driving that may be wrong and that the universe began to slow 1.5 billion years ago â€“ yet other scientists disagree",
      "pubDate": "Thu, 06 Nov 2025 02:38:21 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "A new ion-based quantum computer makes error correction simpler",
      "link": "https://www.technologyreview.com/2025/11/05/1127659/a-new-ion-based-quantum-computer-makes-error-correction-simpler/",
      "description": "The US- and UK-based company Quantinuum today unveiled Helios, its third-generation quantum computer, which includes expanded computing power and error correction capability.Â  Like all other existing quantum computers, Helios is not powerful enough to execute the industryâ€™s dream money-making algorithms, such as those that would be useful for materials discovery or financial modeling. But Quantinuumâ€™sâ€¦",
      "pubDate": "Wed, 05 Nov 2025 21:43:02 +0000",
      "source": "MIT Technology Review",
      "sourceUrl": "https://www.technologyreview.com/feed/",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "New quantum computer is on the path to unravelling superconductivity",
      "link": "https://www.newscientist.com/article/2502688-new-quantum-computer-is-on-the-path-to-unravelling-superconductivity/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Using the Helios-1 quantum computer, researchers have used a record-breaking number of error-proof qubits to run the first and biggest quantum simulation of a model for perfect conductivity",
      "pubDate": "Wed, 05 Nov 2025 20:00:19 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Discoverâ€™s Data Manager Helps Foil Credit Card Fraudsters",
      "link": "https://spectrum.ieee.org/discover-manager-credit-card-fraud",
      "description": "Have you received a notification from your bank or credit card company alerting you to suspicious activity on your account and requesting you confirm a purchase? You probably wondered how the bank suspected the charge wasnâ€™t legitimate.\nCredit card companies use a variety of methods to detect fraud, which is the most common type of identity theft and is on the rise, according to Experian, one of the major consumer credit information services.\nPankaj Gupta\n\nEmployer \nDiscover, in Raleigh, N.C.\nTitle \nData engineering manager\nMember grade \nSenior member\nAlma mater \nChristian College of Engineering and Technology, in Bhilai, India\nTo help prevent unauthorized transactions, IEEE Senior Member Pankaj Gupta is developing tools using data integration, artificial intelligence, machine learning, and real-time account monitoring. Gupta is a manager of data and analytics engineering for Discover, and he works from Raleigh, N.C.\nâ€œThe innovations my fraud department has developed have helped my organization respond to threats faster and adapt more easily to future needs,â€ he says.\nThis year, he received Discoverâ€™s Presidentâ€™s Award, the companyâ€™s highest employee recognition. It is given to those who have achieved outstanding business results while demonstrating the companyâ€™s values.\nGupta also became an invited member of the Forbes Technology Council, a community of experienced leaders across industries, selected based on their professional achievements and leadership experience.\nHe says he enjoys his job but says he never meant to work in financial services, a field where he has built a nearly two-decade-long career.\nFrom electrical engineering to software development\nAs a youngster, he was curious about how things worked and would take apart gadgets his father brought home.\nâ€œMy father worked at BSNL, a government telecom organization, and often took me to his office,â€ Gupta says. â€œThere I would watch phones in operation and telecom operators connecting trunk calls. At home, we even had a few old, nonfunctional phones lying around.â€\nWhile at school, he enjoyed participating in science and math olympiads and exhibitions, he says.\nTaking note of his curiosity and his problem-solving skills, his teachers encouraged him to study engineering. He was most interested in learning electrical engineering because of his interest in the power substations that he and his father checked out.\nâ€œGrowing up in a small town [Dongargarh, which is famous for the Bamleshwari Temple, a popular Hindu pilgrimage site], I saw how technology could help solve problems and make life better for people,â€ he says.\nHe also became fascinated by the nearby steel factoryâ€™s massive machines, its chimneys, and the constant activity around them, he says.\nâ€œI noticed how everything seemed to work together in a coordinated way. Seeing such complex engineering in action at such a young age planted the seed of my interest in technology,â€ he says. â€œThis exposure inspired me to pursue electrical engineering as a career.â€\nIn 2002 he enrolled in the EE program at the Christian College of Engineering and Technology, in Bhilai, India, a 180-minute commute each way by train. He left at 5 a.m. and returned at 6:30 p.m. During his senior year, his family began struggling financially, he says, so his priority was to find a job immediately after graduating to support them.\nIn India, universities hold placement events on campus to recruit graduating students. Gupta says he was lucky enough to receive a job offer from the Indian IT company Satyam Computer Services, which is now defunct. He started there in 2006 after earning his bachelorâ€™s degree in engineering and electrical engineering. Satyam assigned him to work on a software program for a financial services company.\nThatâ€™s when he pivoted to software engineering.\nGupta says that although software development wasnâ€™t his preferred career path, it enabled him to support himself and his parents.\nHe still has a soft spot for electrical engineering, he says, but he hasnâ€™t changed fields or industries for the past 18 years.\nHis time at a variety of financial institutions has allowed him to travel the world to work in other countries including Germany and the United Kingdom, he says. The United States is the fourth country where he has worked.\nâ€œItâ€™s been an exciting journey, learning about different work cultures and technologies,â€ he says.\nUsing AI and machine learning to combat fraud\nGupta left Satyam in 2011 to join Mphasis, an IT solutions company in Bangalore, India, as a senior software developer focused on extracting, transforming, and loading (ETL) data. After a year, he left for Wipro Technologies in Bengaluru. As a technical lead, he was assigned as a consultant for Capital One in Bangalore in an offshore development center. He led a team of 10 employees working on data integration projects including generic frameworks.\nHe moved to the United States in 2017 to work as an associate vice president at JPMorgan Chase in Jersey City, N.J. He helped create a world-class analytics platform and modernize the bankâ€™s reporting systems. He also worked on systems that use a zero-trust security approach, which he describes as one whereby banks do not automatically trust any user or system. Instead, they verify every transaction.\nâ€œThis greatly reduces the risk of fraud or unauthorized access,â€ he says.\nHe also developed scalable data partitioning techniques that organize and split large volumes of information into more manageable pieces.\nâ€œI believe that as AI advances, other innovations will evolve.â€\nâ€œThis allows the system to process data more quickly, handle growth without slowing down, and support real-time decision-making,â€ he says. â€œThese innovations have helped my organization respond to threats faster.â€\nHe joined Discover in 2019 and has worked his way up from principal data engineer for the data and analytics group to manager of data engineering. He developed AI-enhanced data pipelines to train models in making real-time, automated decisions.\nAI and machine learning systems can prevent fraudulent transactions by collecting information about a customerâ€™s typical financial habits over time, such as whether banking is done online or through an app, the time of day transactions occur, and the typical amount paid to creditors. The system is then trained to look for anomalies.\nIn simple terms, the system assigns a risk score to each transaction, usually on a scale based on patterns it has learned, Gupta says. If the score crosses a certain threshold, the bank might take preventive action. If, for instance, there is an unusual purchase in a location far from where the customer lives, the bank will send the customer a message, looking to verify whether the transaction is legitimate. If the customer does not recognize the purchase, the bank blocks the transaction.\nStaying connected to tech pros\nGupta joined IEEE in 2023 â€œto connect with a global network of technology professionals, and to stay updated in the latest advancements in engineering and computing,â€ he says. He was elevated to senior member later that year.\nâ€œMembership has helped me access world-class research through the IEEE Xplore Digital Library,â€ he says. â€œIt also provided me an opportunity to attend conferences and share my expertise with the wider engineering community.â€\nAIâ€™s impact on engineering\nHis advice for young engineers is to stay curious and keep learning.\nâ€œTechnology is changing very rapidly,â€ he says. â€œWhat is working right now might change in six months, so adaptability is your biggest strength.â€\nHe predicts that AI agents will eventually take over repetitive tasks such as those related to automation, coding, and programming. Where engineers will be most needed, he says, is building AI models and training them.\nâ€œEngineers will find significant opportunities for growth in these areas,â€ he says. â€œI believe that as AI advances, other innovations will evolve.\nâ€œFocus on solving real problems, not just building solutions for their own sake.\nâ€œBuild your professional network and seek mentors who can guide you through both technical and career challenges.â€",
      "pubDate": "Wed, 05 Nov 2025 19:00:03 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Here's how to spot the Leonid meteor shower this month",
      "link": "https://www.newscientist.com/article/mg26835680-700-heres-how-to-spot-the-leonid-meteor-shower-this-month/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "A new moon on 20 November means there is a great opportunity to enjoy the Leonid meteor shower this year, says Abigail Beall. Just make sure to get warm and comfy first",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "New Scientist recommends the cult film Hackers â€“ 30 years late",
      "link": "https://www.newscientist.com/article/mg26835680-300-new-scientist-recommends-the-cult-film-hackers-30-years-late/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The books, TV, games and more that New Scientist staff have enjoyed this week",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "The Trump administration is playing peekaboo with reality",
      "link": "https://www.newscientist.com/article/mg26835682-700-the-trump-administration-is-playing-peekaboo-with-reality/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "By cutting surveys of public health, the US government won't be able to properly tackle problems ranging from drug addiction to food insecurity",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "New book tells compelling tale of the fight to save the Siberian tiger",
      "link": "https://www.newscientist.com/article/mg26835680-200-new-book-tells-compelling-tale-of-the-fight-to-save-the-siberian-tiger/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "The battle to save the magnificent but endangered Amur tiger detailed in Jonathan Slaght's Tigers Between Empires is an inspiring look at what collaboration across borders can achieve, finds Adam Weymouth",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Is a robot programmed to prank you annoying? Yes",
      "link": "https://www.newscientist.com/article/mg26835684-200-is-a-robot-programmed-to-prank-you-annoying-yes/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Feedback discovers a robot that can mimic Turkish ice cream vendors, who are known for playing tricks on their customers. Researchers concluded that customers, perhaps predictably, don't trust it",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "This book is a great insight into the new science of microchimerism",
      "link": "https://www.newscientist.com/article/mg26835680-100-this-book-is-a-great-insight-into-the-new-science-of-microchimerism/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Lise BarnÃ©oud's Hidden Guests shows how this fascinating new field brings with it profound implications for medicine, and even what it means to be human, finds Helen Thomson",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Human minds abhor uncertainty. This is a problem for liberal democracy",
      "link": "https://www.newscientist.com/article/mg26835682-500-human-minds-abhor-uncertainty-this-is-a-problem-for-liberal-democracy/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Neurologically, the flexibility of the future promised by liberal democracy can be a challenge because it brings with it uncertainty. But there are solutions, say Florence Gaub and Liya Yu",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Deep-space sci-fi novel is delightful, profound and not to be missed",
      "link": "https://www.newscientist.com/article/mg26835680-400-deep-space-sci-fi-novel-is-delightful-profound-and-not-to-be-missed/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "A planet is about to be destroyed by the collapse of a binary star system in Slow Gods, Claire Northâ€™s first venture into classic science fiction. Read it! says Emily H. Wilson",
      "pubDate": "Wed, 05 Nov 2025 18:00:00 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Lumpy â€˜caterpillar wormholesâ€™ may connect entangled black holes",
      "link": "https://www.newscientist.com/article/2502073-lumpy-caterpillar-wormholes-may-connect-entangled-black-holes/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "A mathematical model suggests that when a pair of black holes gets quantum entangled, this can give rise to a lumpy space-time tunnel between them",
      "pubDate": "Wed, 05 Nov 2025 17:00:18 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "What weâ€™re learning about consciousness from master meditatorsâ€™ brains",
      "link": "https://www.newscientist.com/article/2501144-what-were-learning-about-consciousness-from-master-meditators-brains/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Neuroscientist Matthew Sacchet is revealing how mastering meditation can not only enable transcendental states of bliss, but also reshape how we experience pain and emotion",
      "pubDate": "Wed, 05 Nov 2025 16:00:12 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "How Your Brain Creates â€˜Ahaâ€™ Moments and Why They Stick",
      "link": "https://www.quantamagazine.org/how-your-brain-creates-aha-moments-and-why-they-stick-20251105/",
      "description": "A sudden flash of insight is a product of your brain. Neuroscientists track the neural activity underlying an â€œahaâ€ and how it might boost memory.            \nThe post How Your Brain Creates â€˜Ahaâ€™ Moments and Why They Stick first appeared on Quanta Magazine",
      "pubDate": "Wed, 05 Nov 2025 15:10:10 +0000",
      "source": "Quanta Magazine",
      "sourceUrl": "https://www.quantamagazine.org/feed/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Toxic algae blighting South Australia could pose a global threat",
      "link": "https://www.newscientist.com/article/2503068-toxic-algae-blighting-south-australia-could-pose-a-global-threat/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Researchers warn that the alga Karenia cristata, which has killed around a million animals in Australian waters in one of the biggest algal blooms ever seen, could harm marine life elsewhere",
      "pubDate": "Wed, 05 Nov 2025 14:00:05 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "Inside Hyundaiâ€™s Massive Metaplant",
      "link": "https://spectrum.ieee.org/hyundai-metaplant",
      "description": "When I traveled to Ellabell, Ga., in May to report on Hyundai Motor Groupâ€™s hyperefficient Metaplantâ€”a US $12.6 billion boost to U.S.-based manufacturing of EVs and batteriesâ€”the companyâ€™s timing appeared solid. At this temple of leading-edge factory tech, Ioniq 5 and Ioniq 9 SUVs marched along surgically spotless assembly lines, giving the South Korean automaker a defensible bulwark against the Trump administrationâ€™s tariffs and onshoring fervor.\nBut dark clouds were already gathering. Consumer adoption of EVs had started slowing. The U.S. federal governmentâ€™s $7,500 clean-car tax credit, which had helped hundreds of thousands of people make the leap to EVs, was being phased out.\n Held securely on a yellow jig, a three-row Ioniq 9 SUV glides from station to station in the assembly hall. A view from below shows its generous, 110.3-kilowatt-hour battery pack, which, as in most EVs, sits below the floor of the car. The pack, which is shielded to prevent or limit damage in a collision, is part of an advanced 800-volt architecture for ultrafast DC charging. Christopher Payne/Esto\nNear the Savannah-area factory, I drove a smartly designed Ioniq 9, a three-row SUV tailored to the United Statesâ€™ plus-size tastes. I also saw a battery plant taking shape: a $4.3 billion joint venture between Hyundai and LG Energy Solution, on track to produce lithium-ion cells for Hyundai, Kia, and Genesis models in 2026. That facility is one of 11 low-roofed buildings that encompass 697,000 square meters (70 hectares), their pale green walls designed to blend into the Georgia countryside.\n\n\n\n Backed by $2.1 billion in state subsidies, the Metaplant is the largest public development project in Georgiaâ€™s history. Covering 70 hectares, it is the centerpiece of Hyundaiâ€™s $12.6 billion total investment in the state, including the battery factory built with LG Energy Solution that ICE and other agents raided in September. Christopher Payne/Esto\nThat battery plant made headlines in September, when U.S. Immigration and Customs Enforcement (ICE) agents staged a workplace raid that led to more than 300 South Korean workers being detained and deported.\nThe episode highlighted the transnational cooperationâ€”and tensionsâ€”inherent in importing a leading-edge manufacturing operation, a duality that might be familiar to anyone old enough to recall Japanâ€™s game-changing entry into the U.S. automobile market in the 1970s and â€™80s. The Metaplant is the largest publicly backed project in Georgiaâ€™s history. Its creation was accelerated by the Biden administrationâ€™s pro-EV policies, and it was also the centerpiece of Republican Gov. Brian Kempâ€™s bid to make his state â€œthe electric mobility capital of the country.â€ Now, it was suddenly the latest flashpoint in an ongoing culture-and-trade war.\nAutomakers roll with the punches because they have no choice\n An automated guided vehicle (AGV) prepares to pick up a rack of windshields from an automated trailer unloader, for â€œjust in timeâ€ delivery to an assembly line where Ioniq 5 EVs are being built. There is no human intervention from the time parts arrive at the Metaplantâ€™s loading docks to their installation. Christopher Payne/Esto\n Robots perform myriad tasks, yet human hands are still best for precision work. Jerry Roach, the Metaplantâ€™s assembly manager, says, â€œI want my people doing craftsmanship. I want to pay people well for the things humans do well, and take away the stuff thatâ€™s tedious and boring.â€ Christopher Payne/Esto\nAs with other EV makers facing hurricane-force headwinds, including the U.S. rollback of pollution and fuel-economy rules, Hyundai has chosen to forge ahead with its long-laid plans. Company executives call the Metaplant North Americaâ€™s most automated car factory and the most advanced full-scale factory among Hyundai Motor Co.â€™s 12 global manufacturing facilities. It rivals or surpasses Japanâ€™s most advanced plants, such as the best operated by Toyota. Compared with the near-Dickensian Detroit auto factory that I toiled at in the 1980s, the stunning facility is a veritable MOMA: a modern museum of manufacturing art.\nTo have any chance of one-upping China, car factories elsewhere must become hyperefficient, which includes enlisting armies of AI-controlled robotsâ€”robots that can potentially work 24/7 and never ask for a raise or a lunch break.\nThe factory may eventually employ 8,500 people directly, and 7,000 satellite workers, for an annual capacity of 500,000 carsâ€”more than Teslaâ€™s Texas Gigafactory but less than Teslaâ€™s Shanghai plant. This past summer, just 1,340 humans were sufficient to send a constant stream of two Ioniq models down these gleaming assembly lines. The â€œMeta Prosâ€ working on those lines were earning on average $58,100 a year, which is 35 percent higher than the average in Bryan County, Ga.\nClearly the days of Fordâ€™s River Rouge complex, which employed more than 100,000 in the 1930s, are gone. As in many new factories, youâ€™ll see surprisingly few people beyond the assembly line itself. During my visit, I spotted less than two dozen in a cavernous welding hall, where 475 robots were piecing together car chassis in a whirling, metallic dance. A steel stamping plant was so quiet that no ear protection was required, even as robots stamped out roofs and other body panels, and then stowed them in overhead racks.\nOutside, human workers parked their cars beneath solar roofs that generate up to 5 percent of the plantâ€™s electricity. Meanwhile, a fleet of 21 hydrogen fuel-cell trucks, from the Hyundai-owned Xcient, carries parts from suppliers, emitting zero tailpipe emissions. The automakerâ€™s goal is to obtain 100 percent of the Metaplantâ€™s energy from renewables by 2030.\n An Ioniq 9 body-in-white, the basic steel skeleton of an automobile, leaves the â€œmain buckâ€ section of the body build line. This line is where the vehicleâ€™s floor and sides meet to form a recognizable car. The line adapts to changing production mixes to meet customer orders, with built-in flexibility to assemble future models.Christopher Payne/Esto\n Sparks fly as welding robots piece together the Ioniq 9â€™s â€œbody-in-white,â€ the industry term for the basic steel skeleton of a car, prior to the addition of subassemblies such as the suspension, power train, body trim, and interior. The Metaplantâ€™s welding shop houses about 500 industrial robots.Christopher Payne/Esto\n Robotic welders have revolutionized car manufacturing, joining the parts of an auto body with levels of speed, precision, and safety that humans canâ€™t match. Such advantages reduce labor costs and scrapped materials. Hyundai is also now experimenting with humanoid robots to perform welding tasks.Christopher Payne/Esto\n â€œBody-completeâ€ robots mount front doors onto Ioniq 5s, using machine vision and laser-measurement systems to ensure an exact fit of movable panels on each body. The robots also install mounting bolts to exact torque specifications, all validated to ensure their work meets safety and quality standards.Christopher Payne/Esto\nSmart, silent robots unload trucks\nWhen those trucks roll into docks at the Metaplant, some of the factoryâ€™s 850 robots promptly unload their parts. About 300 automated guided vehicles, or AGVs, glide silently across the factory floor with no tracks required, trained to smartly stop for humans. An AGV rolls beneath a finished Hyundai, squeezes the wheels in its robotic arms, then swiftly hoists and ferries the car where it needs to go. A companion AGV further down the line executes the exact same moves. Iâ€™ve never seen so many robotic sleds like these, or a tag team move with more efficiency and grace. Within an AI-based procurement-and-logistics system, the AGVs allocate and deliver parts to workstations for â€œjust in timeâ€ delivery, avoiding wasted time, space, and money as they stockpile components.\n An automated guided vehicle ferries dashboards for the Hyundai Ioniq 9 SUV, including each dashboardâ€™s pair of 30-centimeter display screens. AGVs are programmed to navigate the factory, using cameras and sensors to slow or stop to avoid collisions, and emit spoken warnings to human workers in their path.Christopher Payne/Esto\nâ€œTheyâ€™re delivering the right parts to the right station at the right time, so youâ€™re no longer relying on people to make those decisions,â€ says Jerry Roach, senior manager of general assembly at the Metaplant.\nRoach prefers that his skilled humans focus on craftsmanship, doing jobs with tactile precision that only human hands and vision can accomplish. The idea is to free people from those elements of factory work that are physically taxing, unfulfilling, and, well, robotic, so workers can use their brains and take pride in their specialized skills.\n Left: Adjustable-height carriers elevate an Ioniq 5 for easy access to the central fasteners and plugs that will position suspension components and the high-voltage battery, prior to the â€œmarriageâ€ between the upper and lower sections of the vehicle. Those carriers provide flexibility for automated functions and manual operations by the human workers at the plant (whom Hyundai calls Meta Pros). Right: On the final assembly line, an Ioniq 9â€™s â€œtop hatâ€â€”including body panelsâ€”is married to the lower â€œskateboardâ€ structure, which includes the electric motors, battery, and suspension. A finished car then undergoes various tests, including a water bath to check for leaks and a quick road test outdoors. Christopher Payne/Esto\nRobots, Roach says, are best tasked with heavy lifting and repetitive tasks, or those that demand digitized speed and accuracy. One example is a â€œcollaborativeâ€ robot, sophisticated enough to work safely in close proximity to people, despite its mammoth strength. For the first time at a Hyundai factory, such a robot is installing bulky, heavy doors on the assembly lineâ€”a notoriously tricky task to perform without scratching the glossy paint or damaging surrounding panels.\n Hyundai is proud of its collaborative robots, including one that can precisely install a heavy door, a tricky task for humans to perform without damaging the panels. Those robots require advanced control systems so that they can work alongside human workers without needing to be fenced off or otherwise isolated.Christopher Payne/Esto\nâ€œGuess what? Robots do that perfectly, always putting the door in the exact same place,â€ Roach says. â€œSo here, that technology makes sense.â€\nManâ€™s best friend, or its mechanical counterparts, stroll the factory floor: Spot, the robotic quadrupeds from Hyundai-owned Boston Dynamics, use camera vision, sensors, and what Boston Dynamics calls â€œathletic intelligenceâ€ to sniff out potential welding defects.\n Spot, the robot dog designed by Hyundai-owned Boston Dynamics, inspects body welds on an Ioniq 5 for defects. Equipped with a sensor suite, the quadruped bot can recharge autonomously, dynamically work around fixed or moving obstacles, and get back on its feet if it falls. Christopher Payne/Esto\nThose four-legged bots may soon have a biped master: Atlas, the humanoid robot, also from Boston Dynamics. The humanoidâ€™s physical dexterity is uncanny, with a 360-degree swiveling head that allows it to walk forward and backward without turning its body. One look at these Atlases crawling, cartwheeling, or breakdancing during testing and you might reasonably conclude theyâ€™re a potential Terminator of jobs. Hyundai executives insist thatâ€™s not the case, even as they plan to put Atlases to work in their global factories. Boston Dynamics is training these robots to sense their environments and manipulate and move parts in complex sequences.\n At this backup station, high-voltage battery fasteners can be installed in an Ioniq 5. The station ensures that the assembly line keeps running even if an automated production system requires servicing. Christopher Payne/Esto\nFrom nearby Interstate 16, Georgia drivers can see freshly painted Ioniq 5s and 9s moving along a conveyor on a windowed bridgeâ€”an intentional glimpse of whatâ€™s happening inside. They can also see their tax dollars at work, after $2.1 billion in state subsidies. Hyundai is already building a second battery plant in Georgia, and a steel plant in Louisiana, part of an expanded pledge of $21 billion in U.S. investment through 2028.\n After their frames are fully welded, Ioniq 5s move along a conveyor [in the background] to an environmentally friendly paint shop. From there, the cars will travel along an elevated bridge, visible from nearby Interstate 16 in Ellabell, Ga., toward final assembly.Christopher Payne/Esto\n An Ioniq 5 arrives at its final inspection station. Immediately after, a human driver gets to drive the pristine car for the first time, on a test track just outside the factory. The first Ioniq 5 rolled off the Metaplant line on 3 October 2024, with the larger Ioniq 9 kicking off production in March 2025. Christopher Payne/Esto\nIn a suddenly inhospitable climate for EVs, thereâ€™s nothing automatic about building and selling the cars. But Hyundai and other automakers will keep trying. They donâ€™t have any other choice.",
      "pubDate": "Wed, 05 Nov 2025 14:00:03 +0000",
      "source": "IEEE Spectrum",
      "sourceUrl": "https://spectrum.ieee.org/rss",
      "credibility": 0.95,
      "category": "tech_news"
    },
    {
      "title": "Ancient DNA may rewrite the story of Iceland's earliest settlers",
      "link": "https://www.newscientist.com/article/2502872-ancient-dna-may-rewrite-the-story-of-icelands-earliest-settlers/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Biochemical evidence suggests Norse people settled in Iceland almost 70 years before the accepted arrival date of the 870s, and didn't chop down the island's forests",
      "pubDate": "Wed, 05 Nov 2025 12:00:34 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    },
    {
      "title": "COP30: Whatâ€™s on the agenda at the BelÃ©m climate summit",
      "link": "https://www.newscientist.com/article/2502476-cop30-whats-on-the-agenda-at-the-belem-climate-summit/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&utm_content=home",
      "description": "Initiatives on the table at COP30 aim to evaluate which countries are most vulnerable, support efforts to clean up industries and pay for the protection of tropical forests",
      "pubDate": "Wed, 05 Nov 2025 08:00:22 +0000",
      "source": "New Scientist",
      "sourceUrl": "https://www.newscientist.com/feed/home/",
      "credibility": 0.9,
      "category": "tech_news"
    }
  ]
}